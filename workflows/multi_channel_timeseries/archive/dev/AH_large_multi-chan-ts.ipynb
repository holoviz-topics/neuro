{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Large - Multi-Channel Timeseries with Dynamic Data Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO create banner image\n",
    "![]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\"> Visit the Index Page </p>\n",
    "    This workflow example is part of set of related workflows. If you haven't already, visit the <a href=\"/index.html\">index</a> page for an introduction and guidance on choosing the appropriate workflow.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intended use-case for this workflow is to browse and annotate multi-channel timeseries data from an [electrophysiological](https://en.wikipedia.org/wiki/Electrophysiology) recording session.\n",
    "\n",
    "Compared to other approaches in this set of workflows, this particular workflow is focused on 'large-sized' datasets, which we define as a dataset that does not comfortably fit into the available RAM.\n",
    "\n",
    "In such cases where the entire dataset cannot be loaded into memory, we have to consider what approaches might work best for scalability. The approach we will demonstrate is one of the most common approaches in the bio-imaging community, and is based on the use of multi-resolution data structures.\n",
    "\n",
    "We will create a derived dataset that includes a multi-resolution pyramid (incrementally downsampled versions of a large dataset), and then use a dynamic accessor to access the appropriate resolution based on viewport and screen parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Resources\n",
    "\n",
    "| Topic | Type | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Intro and Guidance](./index.ipynb) | Prerequisite | Background |\n",
    "| [Time Range Annotation](./time_range_annotation.ipynb) | Next Step | Display and edit time ranges |\n",
    "| [Smaller Dataset Workflow](./small_multi-chan-ts.ipynb) | Alternative | Use Numpy |\n",
    "| [Medium Dataset Workflow](./medium_multi-chan-ts.ipynb) | Alternative | Use Pandas and downsampling |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the libraries necessary to preprocess the data, notably:\n",
    "\n",
    "- `tsdownsample` for downsampling data\n",
    "- `ndpyramid` for creating a multi-resolution pyramid\n",
    "- `datatree` for opening and reading datatrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dask.array as da\n",
    "import datatree as dt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from ndpyramid import pyramid_create\n",
    "from tsdownsample import MinMaxLTTBDownsampler\n",
    "\n",
    "DATA_DIR = os.path.expanduser(\"~/repos/czi/allensdk_cache/session_715093703\")\n",
    "PYRAMID_PATH = os.path.join(DATA_DIR, \"pyramid_neuropix_10s.zarr\")\n",
    "OVERWRITE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize into XArray\n",
    "\n",
    "We use `h5py` to open the HDF5 file and because `xarray` provides an interface with many of the modern data wrangling libraries, we serialize pieces of the data into an `xr.DataArray`. We also wrap `dask` on the data so that it's lazily loaded, i.e. data isn't loaded until necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_to_xarray(f, data_key, dims):\n",
    "    coords = {f[dim] for dim in dims.values()}\n",
    "    data = f[data_key]\n",
    "    ds = xr.DataArray(\n",
    "        da.from_array(data, name=\"data\", chunks=(data.shape[0], 1)),\n",
    "        dims=dims,\n",
    "        coords=coords,\n",
    "    ).to_dataset()\n",
    "    return ds\n",
    "\n",
    "\n",
    "h5py_path = os.path.join(DATA_DIR, \"probe_810755797_lfp.nwb\")\n",
    "f = h5py.File(h5py_path, \"r\")\n",
    "\n",
    "ts_ds = serialize_to_xarray(\n",
    "    f,\n",
    "    \"acquisition/probe_810755797_lfp_data/data\",\n",
    "    {\n",
    "        \"time\": \"acquisition/probe_810755797_lfp_data/timestamps\",\n",
    "        \"channel\": \"acquisition/probe_810755797_lfp_data/electrodes\",\n",
    "    },\n",
    ").isel(channel=slice(10))\n",
    "\n",
    "ts_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataTree\n",
    "\n",
    "Now that we have an `xr.DataArray`, we can perform computations on it in a vectorized & parallelized manner with `xr.apply_ufunc`.\n",
    "\n",
    "Combine it with `ndpyramid.pyramid_create` to create a data tree with various levels containing the downsampled by various factors data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the factors for downsampling, that scale with the number of channels.\n",
    "FACTORS = list(np.array([1, 2, 4, 8, 16, 32, 64, 128, 256]) ** (len(ts_ds[\"channel\"]) // 4))\n",
    "\n",
    "\n",
    "def _help_downsample(data, time, n_out):\n",
    "    \"\"\"\n",
    "    Helper function for downsampling and returning as a specific format.\n",
    "    \"\"\"\n",
    "    indices = MinMaxLTTBDownsampler().downsample(time, data, n_out=n_out)\n",
    "    return data[indices], indices\n",
    "\n",
    "\n",
    "def apply_downsample(ts_ds, factor, dims):\n",
    "    \"\"\"\n",
    "    Apply downsampling to a time series dataset.\n",
    "    \"\"\"\n",
    "    dim = dims[0]\n",
    "    n_out = len(ts_ds[\"data\"]) // factor\n",
    "    print(f\"Downsampling by factor {factor} for a size of {n_out}.\")\n",
    "    ts_ds_downsampled, indices = xr.apply_ufunc(\n",
    "        _help_downsample,\n",
    "        ts_ds[\"data\"],\n",
    "        ts_ds[dim],\n",
    "        kwargs=dict(n_out=n_out),\n",
    "        input_core_dims=[[dim], [dim]],\n",
    "        output_core_dims=[[dim], [\"indices\"]],\n",
    "        exclude_dims=set((dim,)),\n",
    "        vectorize=True,\n",
    "        dask=\"parallelized\",\n",
    "        dask_gufunc_kwargs=dict(output_sizes={dim: n_out, \"indices\": n_out}),\n",
    "    )\n",
    "    ts_ds_downsampled[dim] = ts_ds[dim].isel(time=indices.values[0])\n",
    "    return ts_ds_downsampled.rename(\"data\")\n",
    "\n",
    "\n",
    "if not os.path.exists(PYRAMID_PATH) or OVERWRITE:\n",
    "    ts_dt = pyramid_create(\n",
    "        ts_ds,\n",
    "        factors=FACTORS,\n",
    "        dims=[\"time\"],\n",
    "        func=apply_downsample,\n",
    "        type_label=\"pick\",\n",
    "        method_label=\"pyramid_downsample\",\n",
    "    )\n",
    "    display(ts_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist and Re-open\n",
    "\n",
    "`dt.DataTree`s mirror `xr.DataArray`s in functionality, and so we can easily export it as zarr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PYRAMID_PATH) or OVERWRITE:\n",
    "    ts_dt.to_zarr(PYRAMID_PATH, mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And read it back in just as easily--just be sure to specify the correct engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dt = dt.open_datatree(PYRAMID_PATH, engine=\"zarr\")\n",
    "\n",
    "ts_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Configuration\n",
    "\n",
    "We now import the libraries necessary for interactively utilizing the datatree / pyramid we just created, notably:\n",
    "\n",
    "- `holoviews`, using `bokeh` backend, to build interactive plots\n",
    "- `panel` to create widgets and dashboard\n",
    "- `scipy` for calculating a zscore of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import datatree as dt\n",
    "\n",
    "from bokeh.models.tools import HoverTool, WheelZoomTool\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from scipy.stats import zscore\n",
    "\n",
    "pn.extension()\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "\n",
    "Here, we prepare some metadata about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_ds(ts_dt, level, channel):\n",
    "    \"\"\"\n",
    "    Helper function to extract a dataset at a specific level and channel.\n",
    "    \"\"\"\n",
    "    ds = ts_dt[str(level)].sel(channel=channel).ds\n",
    "    return ds\n",
    "\n",
    "\n",
    "ts_dt = dt.open_datatree(PYRAMID_PATH, engine=\"zarr\")\n",
    "\n",
    "num_levels = len(ts_dt) - 1\n",
    "sel_group = f\"{num_levels}\"\n",
    "time_da = _extract_ds(ts_dt, sel_group, 0)[\"time\"]\n",
    "\n",
    "channels = ts_dt[sel_group].ds[\"channel\"].values\n",
    "num_channels = len(channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dynamic Plot\n",
    "\n",
    "Here we define a `rescale` function that reruns when the axes' ranges (`RangeXY`) or the size of a plot (`PlotSize`) changes.\n",
    "\n",
    "Based on the changes and thresholds, a new plot is created using a new subset of the datatree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PADDING = 0.2  # buffer around x so if user zooms out, data is still visible\n",
    "\n",
    "\n",
    "def rescale(x_range, y_range, width, scale, height):\n",
    "    # fix edge cases when streams are initialized\n",
    "    if x_range is None:\n",
    "        x_range = time_da.min().item(), time_da.max().item()\n",
    "    if y_range is None:\n",
    "        y_range = 0, num_channels\n",
    "    x_padding = (x_range[1] - x_range[0]) * X_PADDING\n",
    "    time_slice = slice(x_range[0] - x_padding, x_range[1] + x_padding)\n",
    "\n",
    "    # calculate the appropriate zoom level and size\n",
    "    if width is None or height is None:\n",
    "        zoom_level = num_levels - 1\n",
    "        size = time_da.size\n",
    "    else:\n",
    "        sizes = [\n",
    "            _extract_ds(ts_dt, zoom_level, 0)[\"time\"].sel(time=time_slice).size\n",
    "            for zoom_level in range(num_levels)\n",
    "        ]\n",
    "        zoom_level = np.argmin(np.abs(np.array(sizes) - width))\n",
    "        size = sizes[zoom_level]\n",
    "\n",
    "    # re-plot the data\n",
    "    curves = hv.Overlay(kdims=\"Channel\")\n",
    "    for channel in channels:\n",
    "        hover = HoverTool(\n",
    "            tooltips=[\n",
    "                (\"Channel\", str(channel)),\n",
    "                (\"Time\", \"$x s\"),\n",
    "                (\"Amplitude\", \"$y µV\"),\n",
    "            ]\n",
    "        )\n",
    "        sub_ds = _extract_ds(ts_dt, zoom_level, channel).sel(time=time_slice).load()\n",
    "        curve = hv.Curve(sub_ds, [\"time\"], [\"data\"], label=f\"ch{channel}\").opts(\n",
    "            color=\"black\",\n",
    "            line_width=1,\n",
    "            subcoordinate_y=True,\n",
    "            subcoordinate_scale=1,\n",
    "            default_tools=[\"pan\", \"reset\", WheelZoomTool(), hover],\n",
    "        )\n",
    "        curves *= curve\n",
    "\n",
    "    # update the title\n",
    "    title = (\n",
    "        f\"level {zoom_level} ({x_range[0]:.2f}s - {x_range[1]:.2f}s) \"\n",
    "        f\"(WxH: {width}x{height}) (length: {size})\"\n",
    "    )\n",
    "    curves = curves.opts(\n",
    "        xlabel=\"Time (s)\",\n",
    "        ylabel=\"Channel\",\n",
    "        title=title,\n",
    "        show_legend=False,\n",
    "        padding=0,\n",
    "        aspect=1.5,\n",
    "        responsive=True,\n",
    "        framewise=True,\n",
    "        axiswise=True,\n",
    "    )\n",
    "    return curves\n",
    "\n",
    "\n",
    "range_stream = hv.streams.RangeXY()\n",
    "size_stream = hv.streams.PlotSize()\n",
    "dmap = hv.DynamicMap(rescale, streams=[size_stream, range_stream])\n",
    "\n",
    "dmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate a Minimap\n",
    "\n",
    "Lastly, we can link a minimap to the main plot to allow for easier navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ts_dt[sel_group].ds[\"data\"].values\n",
    "y_positions = range(num_channels)\n",
    "yticks = [(i, ich) for i, ich in enumerate(channels)]\n",
    "z_data = zscore(data, axis=1)\n",
    "\n",
    "minimap = rasterize(\n",
    "    hv.Image((time_da, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\")\n",
    ").opts(\n",
    "    cnorm='eq_hist',\n",
    "    cmap=\"RdBu_r\",\n",
    "    xlabel=\"\",\n",
    "    yticks=[yticks[0], yticks[-1]],\n",
    "    toolbar=\"disable\",\n",
    "    height=120,\n",
    "    responsive=True,\n",
    "x    alpha=0.8,\n",
    ")\n",
    "\n",
    "tool_link = RangeToolLink(\n",
    "    minimap,\n",
    "    dmap,\n",
    "    axes=[\"x\", \"y\"],\n",
    "    boundsx=(0, time_da.max().item() // 2),\n",
    "    boundsy=(0, len(channels) // 2),\n",
    ")\n",
    "\n",
    "app = (dmap + minimap).cols(1)\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a Widget\n",
    "\n",
    "Currently, the minimap uses only the coarsest level of the datatree. We can create a widget to control the level of granularity the minimap shows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_group = pn.widgets.Select(value=f\"/{sel_group}\", options=list(ts_dt.groups[1:]))\n",
    "\n",
    "\n",
    "def update_minimap(group):\n",
    "    data = ts_dt[group].ds[\"data\"].values\n",
    "    y_positions = range(num_channels)\n",
    "    z_data = zscore(data, axis=1)\n",
    "    time_da = _extract_ds(ts_dt, group, 0)[\"time\"]\n",
    "\n",
    "    minimap = hv.Image(\n",
    "        (time_da, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"\n",
    "    )\n",
    "    return minimap\n",
    "\n",
    "\n",
    "yticks = [(i, ich) for i, ich in enumerate(channels)]\n",
    "minimap = rasterize(\n",
    "    hv.DynamicMap(pn.bind(update_minimap, input_group.param.value)).opts(\n",
    "        cnorm=\"eq_hist\",\n",
    "        cmap=\"RdBu_r\",\n",
    "        xlabel=\"\",\n",
    "        yticks=[yticks[0], yticks[-1]],\n",
    "        toolbar=\"disable\",\n",
    "        height=120,\n",
    "        responsive=True,\n",
    "        alpha=0.8,\n",
    "    )\n",
    ")\n",
    "\n",
    "app = pn.Column(input_group, (dmap + minimap).cols(1))\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Optional:* Standalone App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using HoloViz Panel, we can also set this application as servable so we can launch it in a browser window, outside of a Jupyter Notebook (templates do not work in notebooks at the time of writing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.template.FastListTemplate(main=[app]).servable();  # semi-colon to prevent it from showing output in a notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full app for easy copy/pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import datatree as dt\n",
    "\n",
    "from bokeh.models.tools import HoverTool, WheelZoomTool\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from scipy.stats import zscore\n",
    "\n",
    "pn.extension()\n",
    "hv.extension(\"bokeh\")\n",
    "\n",
    "X_PADDING = 0.2  # buffer around x so if user zooms out, data is still visible\n",
    "\n",
    "\n",
    "def rescale(x_range, y_range, width, scale, height):\n",
    "    # fix edge cases when streams are initialized\n",
    "    if x_range is None:\n",
    "        x_range = time_da.min().item(), time_da.max().item()\n",
    "    if y_range is None:\n",
    "        y_range = 0, num_channels\n",
    "    x_padding = (x_range[1] - x_range[0]) * X_PADDING\n",
    "    time_slice = slice(x_range[0] - x_padding, x_range[1] + x_padding)\n",
    "\n",
    "    # calculate the appropriate zoom level and size\n",
    "    if width is None or height is None:\n",
    "        zoom_level = num_levels - 1\n",
    "        size = time_da.size\n",
    "    else:\n",
    "        sizes = [\n",
    "            _extract_ds(ts_dt, zoom_level, 0)[\"time\"].sel(time=time_slice).size\n",
    "            for zoom_level in range(num_levels)\n",
    "        ]\n",
    "        zoom_level = np.argmin(np.abs(np.array(sizes) - width))\n",
    "        size = sizes[zoom_level]\n",
    "\n",
    "    # re-plot the data\n",
    "    curves = hv.Overlay(kdims=\"Channel\")\n",
    "    for channel in channels:\n",
    "        hover = HoverTool(\n",
    "            tooltips=[\n",
    "                (\"Channel\", str(channel)),\n",
    "                (\"Time\", \"$x s\"),\n",
    "                (\"Amplitude\", \"$y µV\"),\n",
    "            ]\n",
    "        )\n",
    "        sub_ds = _extract_ds(ts_dt, zoom_level, channel).sel(time=time_slice).load()\n",
    "        curve = hv.Curve(sub_ds, [\"time\"], [\"data\"], label=f\"ch{channel}\").opts(\n",
    "            color=\"black\",\n",
    "            line_width=1,\n",
    "            subcoordinate_y=True,\n",
    "            subcoordinate_scale=1,\n",
    "            default_tools=[\"pan\", \"reset\", WheelZoomTool(), hover],\n",
    "        )\n",
    "        curves *= curve\n",
    "\n",
    "    # update the title\n",
    "    title = (\n",
    "        f\"level {zoom_level} ({x_range[0]:.2f}s - {x_range[1]:.2f}s) \"\n",
    "        f\"(WxH: {width}x{height}) (length: {size})\"\n",
    "    )\n",
    "    curves = curves.opts(\n",
    "        xlabel=\"Time (s)\",\n",
    "        ylabel=\"Channel\",\n",
    "        title=title,\n",
    "        show_legend=False,\n",
    "        padding=0,\n",
    "        aspect=1.5,\n",
    "        responsive=True,\n",
    "        framewise=True,\n",
    "        axiswise=True,\n",
    "    )\n",
    "    return curves\n",
    "\n",
    "\n",
    "def _extract_ds(ts_dt, level, channel):\n",
    "    \"\"\"\n",
    "    Helper function to extract a dataset at a specific level and channel.\n",
    "    \"\"\"\n",
    "    ds = ts_dt[str(level)].sel(channel=channel).ds\n",
    "    return ds\n",
    "\n",
    "\n",
    "def update_minimap(group):\n",
    "    data = ts_dt[group].ds[\"data\"].values\n",
    "    y_positions = range(num_channels)\n",
    "    z_data = zscore(data, axis=1)\n",
    "    time_da = _extract_ds(ts_dt, group, 0)[\"time\"]\n",
    "\n",
    "    minimap = hv.Image(\n",
    "        (time_da, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"\n",
    "    )\n",
    "    return minimap\n",
    "\n",
    "\n",
    "ts_dt = dt.open_datatree(PYRAMID_PATH, engine=\"zarr\")\n",
    "\n",
    "num_levels = len(ts_dt) - 1\n",
    "sel_group = f\"{num_levels}\"\n",
    "time_da = _extract_ds(ts_dt, sel_group, 0)[\"time\"]\n",
    "\n",
    "channels = ts_dt[sel_group].ds[\"channel\"].values\n",
    "num_channels = len(channels)\n",
    "\n",
    "range_stream = hv.streams.RangeXY()\n",
    "size_stream = hv.streams.PlotSize()\n",
    "dmap = hv.DynamicMap(rescale, streams=[size_stream, range_stream])\n",
    "\n",
    "input_group = pn.widgets.Select(value=f\"/{sel_group}\", options=list(ts_dt.groups[1:]))\n",
    "yticks = [(i, ich) for i, ich in enumerate(channels)]\n",
    "minimap = rasterize(\n",
    "    hv.DynamicMap(pn.bind(update_minimap, input_group.param.value)).opts(\n",
    "        cnorm=\"eq_hist\",\n",
    "        cmap=\"RdBu_r\",\n",
    "        xlabel=\"\",\n",
    "        yticks=[yticks[0], yticks[-1]],\n",
    "        toolbar=\"disable\",\n",
    "        height=120,\n",
    "        responsive=True,\n",
    "        alpha=0.8,\n",
    "    )\n",
    ")\n",
    "\n",
    "app = pn.Column(input_group, (dmap + minimap).cols(1))\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro-multi-chan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
