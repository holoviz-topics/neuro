{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa351c46-75ba-40db-b6f4-08b78ef08934",
   "metadata": {},
   "source": [
    "# Two Data group example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from holoviews.operation.normalization import subcoordinate_group_ranges\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from scipy.stats import zscore\n",
    "import colorcet as cc\n",
    "\n",
    "hv.extension('bokeh')\n",
    "\n",
    "GROUP_EEG = 'EEG'\n",
    "GROUP_POS = 'Position'\n",
    "N_CHANNELS_EEG = 10\n",
    "N_CHANNELS_POS = 3\n",
    "N_SECONDS = 5\n",
    "SAMPLING_RATE_EEG = 200\n",
    "SAMPLING_RATE_POS = 25\n",
    "INIT_FREQ = 2  # Initial frequency in Hz\n",
    "FREQ_INC = 5  # Frequency increment\n",
    "AMPLITUDE_EEG = 1000  # EEG amplitude multiplier\n",
    "AMPLITUDE_POS = 2  # Position amplitude multiplier\n",
    "\n",
    "# Generate time for EEG and position data\n",
    "total_samples_eeg = N_SECONDS * SAMPLING_RATE_EEG\n",
    "total_samples_pos = N_SECONDS * SAMPLING_RATE_POS\n",
    "time_eeg = np.linspace(0, N_SECONDS, total_samples_eeg)\n",
    "time_pos = np.linspace(0, N_SECONDS, total_samples_pos)\n",
    "\n",
    "# Generate EEG timeseries data\n",
    "def generate_eeg_data(index):\n",
    "    return AMPLITUDE_EEG * np.sin(2 * np.pi * (INIT_FREQ + index * FREQ_INC) * time_eeg)\n",
    "\n",
    "eeg_channels = [str(i) for i in np.arange(N_CHANNELS_EEG)]\n",
    "eeg_data = np.array([generate_eeg_data(i) for i in np.arange(N_CHANNELS_EEG)])\n",
    "eeg_df = pd.DataFrame(eeg_data.T, index=time_eeg, columns=eeg_channels)\n",
    "eeg_df.index.name = 'Time'\n",
    "\n",
    "# Generate position data\n",
    "pos_channels = ['X', 'Y', 'Z'] # avoid lowercase 'x' and 'y' as channel/dimension names\n",
    "pos_data = AMPLITUDE_POS * np.random.randn(N_CHANNELS_POS, total_samples_pos).cumsum(axis=1)\n",
    "pos_df = pd.DataFrame(pos_data.T, index=time_pos, columns=pos_channels)\n",
    "pos_df.index.name = 'Time'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89432c6-ec76-4957-9673-6f7c9114a538",
   "metadata": {},
   "source": [
    "## Create a Curve per data series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9476769f-3935-4236-b010-1511d1a1e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_to_curves(df, kdim, vdim, color='black', group='EEG'):\n",
    "    curves = []\n",
    "    for i, (channel, channel_data) in enumerate(df.items()):\n",
    "        ds = hv.Dataset((channel_data.index, channel_data), [kdim, vdim])\n",
    "        curve = hv.Curve(ds, kdim, vdim, group=group, label=str(channel))\n",
    "        curve.opts(\n",
    "            subcoordinate_y=True, color=color if isinstance(color, str) else color[i], line_width=1, \n",
    "            hover_tooltips=hover_tooltips, tools=['xwheel_zoom'], line_alpha=.8,\n",
    "        )\n",
    "        curves.append(curve)\n",
    "    return curves\n",
    "\n",
    "hover_tooltips = [(\"Group\", \"$group\"), (\"Channel\", \"$label\"), (\"Time\"), (\"Value\")]\n",
    "\n",
    "vdim_EEG = hv.Dimension(\"Value\", unit=\"ÂµV\")\n",
    "vdim_POS = hv.Dimension(\"Value\", unit=\"cm\")\n",
    "time_dim = hv.Dimension(\"Time\", unit=\"s\")\n",
    "\n",
    "eeg_curves = df_to_curves(eeg_df, time_dim, vdim_EEG, color='black', group='EEG')\n",
    "pos_curves = df_to_curves(pos_df, time_dim, vdim_POS, color=cc.glasbey_cool, group='POS')\n",
    "\n",
    "# Combine EEG and POS curves into an Overlay\n",
    "eeg_curves_overlay = hv.Overlay(eeg_curves, kdims=\"Channel\")\n",
    "pos_curves_overlay = hv.Overlay(pos_curves, kdims=\"Channel\")\n",
    "curves_overlay = (eeg_curves_overlay * pos_curves_overlay).opts(\n",
    "    xlabel=time_dim.pprint_label, ylabel=\"Channel\", show_legend=False, aspect=3, responsive=True,\n",
    ")\n",
    "curves_overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9388d59b-c79b-4dc4-94a6-9316594ed4c5",
   "metadata": {},
   "source": [
    "## Apply group-wise normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb78a48-5c6a-4969-bf58-539fce784364",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_overlay = subcoordinate_group_ranges(curves_overlay)\n",
    "normalized_overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd39c14-d9a8-4095-87f9-6bd25bd3dd81",
   "metadata": {},
   "source": [
    "## Minimap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4c745-4ed3-4319-b316-785411a8b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_positions = range(N_CHANNELS_EEG + N_CHANNELS_POS)\n",
    "\n",
    "# Reindex the lower frequency DataFrame to match the higher frequency index\n",
    "pos_df_interp = pos_df.reindex(eeg_df.index).interpolate(method='index')\n",
    "\n",
    "# concatenate the EEG and interpolated POS data and z-score the full data array\n",
    "z_data = zscore(np.concatenate((eeg_df.values, pos_df_interp.values), axis=1), axis=0).T\n",
    "\n",
    "minimap = rasterize(hv.Image((time_eeg, y_positions , z_data), [time_dim, \"Channel\"], \"Value\"))\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\", xlabel='', alpha=.7,\n",
    "    yticks=[(y_positions[0], f'EEG {eeg_channels[0]}'), (y_positions[-1], f'POS {pos_channels[-1]}')],\n",
    "    height=120, responsive=True, toolbar='disable', cnorm='eq_hist'\n",
    ")\n",
    "minimap\n",
    "\n",
    "RangeToolLink(\n",
    "    minimap, normalized_overlay, axes=[\"x\", \"y\"],\n",
    "    boundsx=(.5, 3), boundsy=(1.5, 12.5),\n",
    "    intervalsx=(None, 3),\n",
    ")\n",
    "\n",
    "dashboard = (normalized_overlay + minimap).cols(1).opts(shared_axes=False)\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f7bae-9ec3-4d0c-9621-386fdabaeedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c771121-a6f7-4d85-805a-1e57cec3ea07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da00f4-8ab1-419a-bb01-d8ef07e4e233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0139f461-8cb4-4c55-be31-fd3ee29e8d04",
   "metadata": {},
   "source": [
    "# NdOverlay and group, channel key to demo wide df issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee0c7b-5bba-4b55-8300-902bbcca5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import colorcet as cc\n",
    "hv.extension('bokeh')\n",
    "\n",
    "GROUP_EEG = 'EEG'\n",
    "N_CHANNELS_EEG = 31\n",
    "N_SECONDS = 5\n",
    "SAMPLING_RATE_EEG = 100\n",
    "INIT_FREQ = 2  # Initial frequency in Hz\n",
    "FREQ_INC = 5  # Frequency increment\n",
    "AMPLITUDE_EEG = 1000  # Amplitude multiplier\n",
    "\n",
    "# Generate data\n",
    "total_samples_eeg = N_SECONDS * SAMPLING_RATE_EEG\n",
    "time_eeg = np.linspace(0, N_SECONDS, total_samples_eeg)\n",
    "def generate_eeg_data(index):\n",
    "    return AMPLITUDE_EEG * np.sin(2 * np.pi * (INIT_FREQ + index * FREQ_INC) * time_eeg)\n",
    "eeg_channels = [str(i) for i in np.arange(N_CHANNELS_EEG)]\n",
    "eeg_data = np.array([generate_eeg_data(i) for i in np.arange(N_CHANNELS_EEG)])\n",
    "eeg_df = pd.DataFrame(eeg_data.T, index=time_eeg, columns=eeg_channels)\n",
    "eeg_df.index.name = 'Time'\n",
    "\n",
    "# Create plot\n",
    "time_dim = hv.Dimension(\"Time\", unit=\"s\")\n",
    "curves = {}\n",
    "for col in eeg_df.columns:\n",
    "    curve = hv.Curve(eeg_df[col], time_dim, hv.Dimension(col, label='Amplitude', unit='uV'),\n",
    "                     label=str(col))\n",
    "    curve = curve.opts(subcoordinate_y=True, tools=['xwheel_zoom', 'hover'], color='grey',\n",
    "                      )\n",
    "    curves['EEG', col] = curve\n",
    "\n",
    "curves_overlay = hv.NdOverlay(curves, [\"Group\", \"Channel\"], sort=False).opts(\n",
    "    xlabel=time_dim.pprint_label, ylabel=\"Channel\", show_legend=False, aspect=3, responsive=True,\n",
    "    min_height=600,\n",
    ")\n",
    "print(curves_overlay)\n",
    "curves_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e08528-a575-4d6a-a0ea-7f3f03d9ef25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd2c3a-0896-44ee-a9c6-2ce732cb3aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "829044cf-f1a0-49dd-bbfb-2a9e9e462be9",
   "metadata": {},
   "source": [
    "# NdOverlay with wide df and hover_tooltips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805bec7-5f8a-4d49-9b7f-15b90daa250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import colorcet as cc\n",
    "hv.extension('bokeh')\n",
    "\n",
    "GROUP_EEG = 'EEG'\n",
    "N_CHANNELS_EEG = 31\n",
    "N_SECONDS = 5\n",
    "SAMPLING_RATE_EEG = 100\n",
    "INIT_FREQ = 2  # Initial frequency in Hz\n",
    "FREQ_INC = 5  # Frequency increment\n",
    "AMPLITUDE_EEG = 1000  # Amplitude multiplier\n",
    "\n",
    "# Generate data\n",
    "total_samples_eeg = N_SECONDS * SAMPLING_RATE_EEG\n",
    "time_eeg = np.linspace(0, N_SECONDS, total_samples_eeg)\n",
    "def generate_eeg_data(index):\n",
    "    return AMPLITUDE_EEG * np.sin(2 * np.pi * (INIT_FREQ + index * FREQ_INC) * time_eeg)\n",
    "eeg_channels = [str(i) for i in np.arange(N_CHANNELS_EEG)]\n",
    "eeg_data = np.array([generate_eeg_data(i) for i in np.arange(N_CHANNELS_EEG)])\n",
    "eeg_df = pd.DataFrame(eeg_data.T, index=time_eeg, columns=eeg_channels)\n",
    "eeg_df.index.name = 'Time'\n",
    "\n",
    "# Create plot\n",
    "time_dim = hv.Dimension(\"Time\", unit=\"s\")\n",
    "curves = {}\n",
    "for col in eeg_df.columns:\n",
    "    curve = hv.Curve(eeg_df[col], time_dim, hv.Dimension(col, label='Amplitude', unit='uV'),\n",
    "                     group='EEG', label=str(col))\n",
    "    curve = curve.opts(subcoordinate_y=True, tools=['xwheel_zoom'], color='grey',\n",
    "                      hover_tooltips = [(\"Group\", \"$group\"), (\"Channel\", \"$label\"), (\"Time\"), (\"Amplitude\")])\n",
    "    curves[('EEG', col)] = curve\n",
    "\n",
    "curves_overlay = hv.NdOverlay(curves, [\"Group\", \"Channel\"], sort=False).opts(\n",
    "    xlabel=time_dim.pprint_label, ylabel=\"Channel\", show_legend=False, aspect=3, responsive=True,\n",
    "    min_height=600, title='Multi-Chan TS'\n",
    ")\n",
    "print(curves_overlay)\n",
    "curves_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06576c9c-aeab-4a88-b624-e4c578b81954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
