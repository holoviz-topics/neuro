{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium - Multi-Channel Timeseries with Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO create banner image\n",
    "![]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\"> Visit the Intro Page </p>\n",
    "    Explore related workflows in this series. For a guided introduction and help with selecting the most suitable workflow, please visit the <a href=\"index.ipynb\">Introduction and Selection Guide</a> page.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow is tailored for processing and analyzing medium-sized multi-channel timeseries data derived from [electrophysiological](https://en.wikipedia.org/wiki/Electrophysiology) recordings.\n",
    "\n",
    "### What Defines a 'Medium-Sized' Dataset?\n",
    "\n",
    "A medium-sized dataset typically includes more than 100,000 samples (data points) and can be handled within the available RAM without exhausting system resources. However, these datasets can still strain the processing capabilities when visualizing or analyzing data directly in the browser. To address this challenge, we will employ downsampling.\n",
    "\n",
    "### Why Downsample?\n",
    "\n",
    "Downsampling is a technique for reducing the dataset size by selectively sampling every few data points, depending on the downsampling algorithm employed. For instance, we'll make use of a downsampling algorithm called [Largest Triangle Three Buckets (LTTB)](https://skemman.is/handle/1946/15343). LTTB allows data points not contributing significantly to the visible shape to be dropped, reducing the amount of data to send to the browser but preserving the appearance (and particularly the envelope, i.e. highest and lowest values in a region). This ensures efficient data handling and visualization without significant loss of information.\n",
    "\n",
    "Downsampling is particularly beneficial when dealing with numerous timeseries sharing a common time index, as it allows for a consolidated slicing operation across all series, significantly reducing the computational load and enhancing responsiveness for interactive visualization. We'll make use of a [Pandas](https://pandas.pydata.org/docs/index.html) index to represent the time index across all timeseries.\n",
    "\n",
    "### Introduction to MNE (MNE-Python)\n",
    "\n",
    "[MNE (MNE-Python)](https://mne.tools/stable/index.html) is an open-source Python library designed specifically for analyzing data like EEG and MEG. In this workflow, since we are using a demo EEG dataset, we use MNE for loading, preprocessing, and conversion to Pandas. However, the data visualization section is highly generalizable to dataset types beyond the scope of MNE, as you can get your data into a Pandas DataFrame with a time index and channel columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Resources\n",
    "\n",
    "| Topic | Type | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Introduction and Selection Guide](./index.ipynb) | Prerequisite | Read the foundational concepts and workflow selection assistance. |\n",
    "| [Time Range Annotation](./time_range_annotation.ipynb) | uggested Next Step | Learn to display and edit time ranges in data. |\n",
    "| [Handling Smaller Datasets](./small_multi-chan-ts.ipynb) | Alternative Workflow | Use Numpy for flexibility with smaller datasets |\n",
    "| [Handling Larger Datasets](./large_multi-chan-ts.ipynb) | Alternative Workflow | Discover techniques for dynamic data chunking in larger datasets. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import colorcet as cc\n",
    "import holoviews as hv\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from holoviews.operation.downsample import downsample1d\n",
    "from bokeh.models import HoverTool\n",
    "import panel as pn\n",
    "\n",
    "pn.extension()\n",
    "hv.extension('bokeh')\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Inspecting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some data! This section walks through obtaining an EEG dataset (2.6 MB). If it doesn't already exist, it will put the data in a new 'data' folder in the same directory of this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R04.edf'\n",
    "output_directory = Path('./data')\n",
    "\n",
    "output_directory.mkdir(parents=True, exist_ok=True)\n",
    "data_path = output_directory / Path(data_url).name\n",
    "if not data_path.exists():\n",
    "    data_path = wget.download(data_url, out=str(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is downloaded, the next crucial step is to load it into an analysis-friendly format and inspect its basic characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(data_path, preload=True)\n",
    "print('num samples in dataset:', len(raw.times) * len(raw.ch_names))\n",
    "raw # Could also use `raw.info`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step confirms the successful loading of the data and provides an initial understanding of its structure, such as the number of channels and samples.\n",
    "\n",
    "Now, let's preview the channel names, types, unit, and signal ranges. This `describe` method is from MNE, and we can have it return a Pandas DataFrame, from which we can `sample` some rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.describe(data_frame=True).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Reduction via Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant noise reduction is often achieved by employing an average reference, which involves calculating the mean signal across all channels at each time point and subtracting it from the individual channel signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.set_eeg_reference(\"average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Channel Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output of the `describe` method, it looks like the channels are from commonly used standardized locations (e.g. 'Cz'), but contain some unnecessary periods, so let's clean those up to ensure smoother processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.rename_channels(lambda s: s.strip(\".\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Enhancing Channel Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing physical locations of EEG channels enhances interpretative analysis. MNE has functionality to assign locations of the channels based on their standardized channel names, so we can go ahead and assign a commonly used arrangement (or 'montage') of electrodes ('10-05') to this data. Read more about making and setting the montage [here](https://mne.tools/stable/auto_tutorials/intro/40_sensor_locations.html#sphx-glr-auto-tutorials-intro-40-sensor-locations-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "raw.set_montage(montage, match_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the 'digitized points' (locations) are now added to the raw data.\n",
    "\n",
    "Now let's plot the channels using MNE [`plot_sensors`](https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.plot_sensors) on a top-down view of a head. Note, we'll tweak the reference point so that all the points are contained within the depiction of the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere=(0, 0.015, 0, 0.099) # manually adjust the y origin coordinate and radius\n",
    "raw.plot_sensors(show_names=True, sphere=sphere);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "### Preparing Data for Visualization\n",
    "\n",
    "We'll use an MNE method, `to_data_frame`, to create a Pandas DataFrame. By default, MNE will convert EEG data from Volts to microVolts (µV) during this operation.\n",
    "\n",
    "TODO: file issue about rangetool not working with datetime (timezone error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw.to_data_frame() # TODO: add time_format='datetime'\n",
    "df.set_index('time', inplace=True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Main Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of the time of writing, there's no easy way to track units with Pandas, so we can use a modular HoloViews approach to create and annotate dimensions with a unit, and then refer to these dimensions when plotting. Read more about annotating data with HoloViews [here](https://holoviews.org/user_guide/Annotating_Data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_dim = hv.Dimension(\"amplitude\", unit=\"µV\")\n",
    "time_dim = hv.Dimension(\"time\", unit=\"s\") # match the index name in the df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will loop over the columns (channels) in the dataframe, creating a HoloViews `Curve` element from each. Since each column in the df has a different name, we will use the `redim` method to map from the channel name to the common `amplitude_dim`. We'll set the Curve label to be the original channel name so we can still see this info in the hover tooltip.\n",
    "\n",
    "In configuring these curves, we apply the `.opts` method from HoloViews to fine-tune the visualization properties of each curve. Two significant settings are `hover_tooltip` and `subcoordinate_y`. The `hover_tooltip` feature, introduced in HoloViews version 1.19.0, enhances user interactivity by allowing customization of the tooltip content that appears when hovering over data points, including the inclusion of 'group' and 'label' data. You can explore further details on configuring hover_tooltip [here](https://holoviews.org/user_guide/Plotting_with_Bokeh.html).\n",
    "\n",
    "The subcoordinate_y feature, available since HoloViews 1.18.0, is pivotal for managing time-aligned, amplitude-diverse plots. When enabled, it arranges each curve along its own segment of the y-axis within a single composite plot. This method not only aids in differentiating the data visually but also in analyzing comparative trends across multiple channels, ensuring that each channel's data is individually accessible and comparably presentable, thereby enhancing the analytical value of the visualizations. Read more about `subcoordinate_y` [here](https://holoviews.org/user_guide/Customizing_Plots.html#subcoordinate-y-axis). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = {}\n",
    "for channel_name, channel_data in df.items():\n",
    "    \n",
    "    curve = hv.Curve(df, kdims=[time_dim], vdims=[channel_name], group=\"EEG\", label=channel_name)\n",
    "\n",
    "    curve = curve.redim(**{channel_name: amplitude_dim}) # TODO this currently prevents the indexing optimization. Without it, downsample1d errors.\n",
    "\n",
    "    curve = curve.opts(\n",
    "        subcoordinate_y=True,\n",
    "        subcoordinate_scale=2,\n",
    "        color=\"black\",\n",
    "        line_width=1,\n",
    "        tools=[\"hover\"],\n",
    "        hover_tooltips=[\n",
    "            (\"type\", \"$group\"),\n",
    "            (\"channel\", \"$label\"),\n",
    "            (\"time\"),  # TODO: '@time{%H:%M:%S.%3N}'),\n",
    "            (\"amplitude\", \"@{channel_name}\"),\n",
    "        ],\n",
    "        # TODO: hover_formatters = {'time': 'datetime'},\n",
    "    )\n",
    "    curves[channel_name] = curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a HoloViews `Overlay` container, we can now overlay all the curves on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves_overlay = hv.Overlay(curves, kdims=\"channel\").opts(\n",
    "    ylabel=\"channel\",\n",
    "    show_legend=False,\n",
    "    padding=0,\n",
    "    aspect=1.5,\n",
    "    responsive=True,\n",
    "    shared_axes=False,\n",
    "    framewise=False,\n",
    "    min_height=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 64 channels and over a million data samples, we'll make use of downsampling before trying to send all that data to the browser. We can use `downsample1d` imported from HoloViews. Starting in HoloViews version 1.19.0, integration with the `tsdownsample` library introduces enhanced downsampling algorithms. Read more about downsampling [here](https://holoviews.org/user_guide/Large_Data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO: still has a bug with navigation in the minimap.\n",
    "- TODO: remove the extra hover tooltip icons in the toolbar (I think all come from custom hover tools). File issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves_overlay = downsample1d(curves_overlay, algorithm='minmax-lttb')\n",
    "curves_overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension: Minimap\n",
    "\n",
    "To assist in navigating the dataset, we integrate a minimap widget. This secondary minimap plot provides a condensed overview of the entire dataset, allowing users to select and zoom into areas of interest quickly in the main plot while maintaining the contextualization of the zoomed out view.\n",
    "\n",
    "We will employ datashader rasterization of the image for the minimap plot to display a browser-friendly, aggregated view of the entire dataset. Read more about datashder rasterization via HoloViews [here](https://holoviews.org/user_guide/Large_Data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = df.columns\n",
    "time = df.index.values\n",
    "\n",
    "y_positions = range(len(channels))\n",
    "yticks = [(i, ich) for i, ich in enumerate(channels)]\n",
    "z_data = zscore(df, axis=0).T\n",
    "minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time\", \"Channel\"], \"amplitude\"))\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\",\n",
    "    colorbar=False,\n",
    "    xlabel='',\n",
    "    alpha=0.5,\n",
    "    yticks=[yticks[0], yticks[-1]],\n",
    "    toolbar='disable',\n",
    "    height=120,\n",
    "    responsive=True,\n",
    "    default_tools=[],\n",
    "    cnorm='eq_hist'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The connection between the main plot and the minimap is facilitated by a `RangeToolLink`, enhancing user interaction by synchronizing the visible range of the main plot with selections made on the minimap. Optionally, we'll also constrain the initially displayed x-range view to a third of the duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RangeToolLink(minimap, curves_overlay, axes=[\"x\", \"y\"],\n",
    "              boundsx=(0, time[len(time)//3]) # limit the initial x-range of the minimap\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll arrange the main plot and minimap into a single column layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = (curves_overlay + minimap).cols(1)\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Extension:* Standalone App\n",
    "This layout, combined with the capabilities of HoloViz Panel, allows for the deployment of this complex visualization as a standalone, template-styled, interactive web application (outside of a Jupyter Notebook). Read more about Panel [here](https://panel.holoviz.org/).\n",
    "\n",
    "In short, we'll add our plot to the `main` area of a Panel Template (for styling), and set it to be `servable`. We'll also set the `aspect` option of the overlay to `None` so that the external plot will fit the entire area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pn.template.FastListTemplate(\n",
    "    title = \"Medium Multi-Chanel Timeseries App\",\n",
    "    main = pn.pane.HoloViews(layout.opts(hv.opts.Overlay(aspect=None)))\n",
    ").servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the same conda environment, you can use `panel serve <path-to-this-file>` on the command line to view the standalone application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Code Block \n",
    "\n",
    "For an easy copy-paste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import colorcet as cc\n",
    "import holoviews as hv\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from holoviews.operation.downsample import downsample1d\n",
    "from bokeh.models import HoverTool\n",
    "import panel as pn\n",
    "\n",
    "pn.extension()\n",
    "hv.extension('bokeh')\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "data_url = 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R04.edf'\n",
    "output_directory = Path('./data')\n",
    "\n",
    "output_directory.mkdir(parents=True, exist_ok=True)\n",
    "data_path = output_directory / Path(data_url).name\n",
    "if not data_path.exists():\n",
    "    data_path = wget.download(data_url, out=str(data_path))\n",
    "\n",
    "raw = mne.io.read_raw_edf(data_path, preload=True);\n",
    "\n",
    "raw.set_eeg_reference(\"average\");\n",
    "\n",
    "raw.rename_channels(lambda s: s.strip(\".\"));\n",
    "\n",
    "df = raw.to_data_frame(); # TODO: add time_format='datetime'\n",
    "df.set_index('time', inplace=True) \n",
    "\n",
    "amplitude_dim = hv.Dimension(\"amplitude\", unit=\"µV\")\n",
    "time_dim = hv.Dimension(\"time\", unit=\"s\")\n",
    "\n",
    "curves = {}\n",
    "for channel_name, channel_data in df.items():\n",
    "    \n",
    "    curve = hv.Curve(df, kdims=[time_dim], vdims=[channel_name], group=\"EEG\", label=channel_name)\n",
    "\n",
    "    curve = curve.redim(**{channel_name: amplitude_dim}) # TODO this currently prevents the indexing optimization. Without it, downsample1d errors.\n",
    "\n",
    "    curve = curve.opts(\n",
    "        subcoordinate_y=True,\n",
    "        subcoordinate_scale=2,\n",
    "        color=\"black\",\n",
    "        line_width=1,\n",
    "        tools=[\"hover\"],\n",
    "        hover_tooltips=[\n",
    "            (\"type\", \"$group\"),\n",
    "            (\"channel\", \"$label\"),\n",
    "            (\"time\"),  # TODO: '@time{%H:%M:%S.%3N}'),\n",
    "            (\"amplitude\", \"@{channel_name}\"),\n",
    "        ],\n",
    "        # TODO: hover_formatters = {'time': 'datetime'},\n",
    "    )\n",
    "    curves[channel_name] = curve\n",
    "\n",
    "    curves_overlay = hv.Overlay(curves, kdims=\"channel\").opts(\n",
    "    ylabel=\"channel\",\n",
    "    show_legend=False,\n",
    "    padding=0,\n",
    "    aspect=1.5,\n",
    "    responsive=True,\n",
    "    shared_axes=False,\n",
    "    framewise=False,\n",
    "    min_height=100,\n",
    ")\n",
    "\n",
    "curves_overlay = downsample1d(curves_overlay, algorithm='minmax-lttb')\n",
    "\n",
    "channels = df.columns\n",
    "time = df.index.values\n",
    "\n",
    "y_positions = range(len(channels))\n",
    "yticks = [(i, ich) for i, ich in enumerate(channels)]\n",
    "z_data = zscore(df, axis=0).T\n",
    "minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time\", \"Channel\"], \"amplitude\"))\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\",\n",
    "    colorbar=False,\n",
    "    xlabel='',\n",
    "    alpha=0.5,\n",
    "    yticks=[yticks[0], yticks[-1]],\n",
    "    toolbar='disable',\n",
    "    height=120,\n",
    "    responsive=True,\n",
    "    default_tools=[],\n",
    "    cnorm='eq_hist'\n",
    "    )\n",
    "\n",
    "RangeToolLink(minimap, curves_overlay, axes=[\"x\", \"y\"],\n",
    "              boundsx=(0, time[len(time)//3]) # limit the initial x-range of the minimap\n",
    "             )\n",
    "\n",
    "layout = (curves_overlay + minimap).cols(1)\n",
    "\n",
    "layout\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
