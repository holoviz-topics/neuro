{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4bd63bd-408b-4357-925c-7a584a9df9a9",
   "metadata": {},
   "source": [
    "# Video Viewer (for Calcium Imaging)\n",
    "![status](https://img.shields.io/badge/status-in%20progress-orange)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2396b7be-9cb7-4eef-b065-048498ab20fa",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./assets/230620_video-viewer.png\" alt=\"video viewer preview\" width=\"450\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578fe7e5-61ce-434c-a046-0bce0e3b1291",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f924e6df-01e8-4be4-8fa4-12178008b1ff",
   "metadata": {},
   "source": [
    "This workflow is intended to demonstrate the visualization of a Calcium Imaging  image stack with HoloViz and Bokeh tools.\n",
    "\n",
    "For details specific to this workflow, such as goals, specifications, and bottlenecks, please this workflow's [readme](./readme_eeg-viewer.md).\n",
    "\n",
    "For a summary of Calcium Imaging research, data, and software, please see [neuro/wiki/Calcium-Imaging-notes](https://github.com/holoviz-topics/neuro/wiki/Calcium-Imaging-notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da0041-a313-42b7-86dd-c81dc0e3f26c",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a52df8-8782-4be8-98b0-f19eaf741c3c",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "<p><strong> Requirements</strong></p>\n",
    "\n",
    "This workflow notebook requires the [environment](./environment.yml) specified in this workflow directory.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc065513-3ed2-408f-bf07-342dc013e523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from neurodatagen.ca_imaging import simulate_miniscope_data\n",
    "\n",
    "import os, sys\n",
    "import panel as pn; pn.extension(throttled=False) # set throttled=True to delay computation until slider lands\n",
    "import hvplot.xarray\n",
    "import holoviews as hv; hv.extension('bokeh')\n",
    "from holoviews.streams import Stream\n",
    "import param\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36035e-db83-408e-b2ad-2ea1608f66f3",
   "metadata": {},
   "source": [
    "## Synthetic data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519826b-741c-46bd-8dd4-db57834de8d2",
   "metadata": {},
   "source": [
    "### Generate synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d61ed-133a-44cf-9870-7aa1ba28d7da",
   "metadata": {},
   "source": [
    "The `simulate_miniscope_data` function generates synthetic calcium imaging data by simulating neural activity through spatial footprints and temporal calcium traces, while incorporating motion artifacts and realistic background noise. \n",
    "\n",
    "The function outputs a numpy array of 8-bit unsigned integers, encapsulated within an `xarray.DataArray`. This array represents the generated imaging data with dimensions corresponding to frame height, frame width, and frame number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1b69c-8123-4c47-8ea1-c8fcb0fcab03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncell = 50\n",
    "dims = {'height': 512, 'width': 512, 'frame': 1000}\n",
    "arr_name='sim_miniscope'\n",
    "chk_size = 200 # chunk size of frames\n",
    "dpath = '~/data/miniscope_simulated.zarr' # location to be stored to or loaded from\n",
    "chunks = {'frame': chk_size} # chunk by set of complete frames\n",
    "\n",
    "data = simulate_miniscope_data(ncell=ncell, dims=dims, arr_name=arr_name, chk_size=chk_size)\n",
    "data\n",
    "\n",
    "# **TODO** set chunks here\n",
    "# **TODO:** add option to generate data straight to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86380a4-c76f-482c-b92c-41386e68ca71",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c286f25-cc4a-4480-8bdb-e47cd1d8c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to disk to mimic a common workflow\n",
    "\n",
    "write = True # turn on to save write data\n",
    "if write:\n",
    "    data.to_zarr(dpath, mode='w') # parallel storage of the different output chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2835131-5a86-46aa-86bd-3338e28433be",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e3aa1-69c6-4947-a1ab-866cd0e1c854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ldataset = xr.open_dataset(dpath, engine='zarr', chunks=chunks) # TODO: why need to specify chunks on read? should use zarr chunking by default\n",
    "data = ldataset[arr_name]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4531c74d-856c-4a89-86f5-862f8b07b121",
   "metadata": {},
   "source": [
    "### Visualize synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4c9c18-ae38-4946-9659-71876b581125",
   "metadata": {},
   "source": [
    "#### Version 1: Simple viewer, hvplot, default slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc25d2b-4e19-4708-a647-3f886f77d263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.hvplot.image(groupby=\"frame\", cmap=\"Viridis\", height=400, width=400, colorbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c633f0-40f8-4707-b615-122ebcea9a49",
   "metadata": {},
   "source": [
    "#### Version 1.1: Simple viewer, hvplot interactive, default slider, no groupby\n",
    "\n",
    "This version avoids the use of `groupby` on a dask array because this can sometimes be a costly operation, see [this.](https://docs.xarray.dev/en/latest/user-guide/dask.html#dask:~:text=More%20generally%2C%20groupby()%20is%20a%20costly%20operation%20and%20will%20perform%20a%20lot%20better%20if%20the%20flox%20package%20is%20installed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ebbad-eedb-4804-a1cf-80fe53b88aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = data.coords[\"frame\"].values\n",
    "slider = pn.widgets.IntSlider(start=int(frames.min()), end=int(frames.max()))\n",
    "frame = data.interactive().isel(frame=slider)\n",
    "frame.hvplot.image(cmap=\"Viridis\", height=400, width=400, colorbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45081ae-47e9-4087-ace0-2179d3c304cf",
   "metadata": {},
   "source": [
    "#### Version 2: Intermediate viewer, hvPlot, Player Widget, frame dim views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fe69c-20ac-4c06-ac6f-b45793afbf00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs = 30 # frames per second\n",
    "frames = data.coords[\"frame\"].values\n",
    "\n",
    "video_player = pn.widgets.Player(\n",
    "    length=len(data.coords[\"frame\"]),\n",
    "    interval=1000//fs, # ms per frame\n",
    "    value=int(frames.min()),\n",
    "    max_width=400,\n",
    "    max_height=90,\n",
    "    loop_policy=\"loop\",\n",
    "    sizing_mode=\"stretch_width\",\n",
    ")\n",
    "\n",
    "main_h_w = data.hvplot.image(\n",
    "    groupby=\"frame\",\n",
    "    cmap=\"Viridis\",\n",
    "    frame_height=400,\n",
    "    frame_width=400,\n",
    "    colorbar=False,\n",
    "    widgets={\"frame\": video_player},\n",
    ")\n",
    "\n",
    "def update_vline(value):\n",
    "    return hv.VLine(value)\n",
    "\n",
    "def update_hline(value):\n",
    "    return hv.HLine(value)\n",
    "\n",
    "dmap_vline = hv.DynamicMap(update_vline, streams=[video_player.param.value]).opts(color='red', alpha=.6, line_width=3)\n",
    "dmap_hline = hv.DynamicMap(update_hline, streams=[video_player.param.value]).opts(color='red', alpha=.6, line_width=3)\n",
    "\n",
    "height_frame_neighbor = data.mean(['width']).hvplot.image(x='frame',\n",
    "    cmap=\"Viridis\",\n",
    "    frame_height=400,\n",
    "    frame_width=200,\n",
    "    colorbar=False,\n",
    "    title='_', # hack to ensure that xlabel is rendered, see https://github.com/bokeh/bokeh/issues/13225#issuecomment-1611172355\n",
    ") * dmap_vline\n",
    "\n",
    "# Ideally, we want the frame_width_neighbor to have yaxis inverted so it progresses away from main like height_frame_neighbor\n",
    "frame_width_neighbor = data.mean(['height']).hvplot.image(y='frame',\n",
    "    cmap=\"Viridis\",\n",
    "    frame_height=200,\n",
    "    frame_width=400,\n",
    "    colorbar=False,\n",
    ") * dmap_hline # invert_yaxis=True doesn't work here, see https://github.com/holoviz/holoviews/issues/5801\n",
    "    # ylim = (data.frame.size-1,0), # this is supposed to be a inver_yaxis workaround but doesn't work here, from https://discourse.holoviz.org/t/hvplot-image-invert-y-axis/5625/2?u=droumis\n",
    "\n",
    "video_player.margin = (20, 20, 20, 70) # hack to center widget over main\n",
    "# main_h_w[0] below selects just the plot so we can handle the widget placement explicitly\n",
    "pn.Column(video_player, pn.Row(main_h_w[0], height_frame_neighbor), frame_width_neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0facf-2fa3-4fb6-9437-3cdbb275ba21",
   "metadata": {},
   "source": [
    "## Real data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4981f70-361a-4b2e-84a3-0d972a68d134",
   "metadata": {},
   "source": [
    "### Intake data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf5f19c-2f95-4fa5-a599-57437f45880f",
   "metadata": {},
   "source": [
    "#### The minian repository includes some demo data. \n",
    "\n",
    "**Option 1 (recommended):** Clone from the forked source:\n",
    "\n",
    "1. `cd <location where minian should be downloaded>`\n",
    "2. `git clone git@github.com:droumis/minian.git`\n",
    "\n",
    "Now you have about 722 MB of .avi files in `minian/demo_movies` and another `10 MB` of .nc files in `minian/demo_data`. Note, this is a fork of the real repository with (currently) minor changes to work with latest xarray version.\n",
    "\n",
    "**Option 2:** follow [conda install instructions](https://minian.readthedocs.io/en/stable/start_guide/install.html#install-using-conda), then run [`minian-install --demo`](https://minian.readthedocs.io/en/stable/start_guide/install.html#getting-notebooks-and-demos). Note, there is no conda installable package for minian on osx_arm64 (M1) macos systems so option 1 is highly recommended in this context. The remaining steps, like setting `sys.path.append` assume **option 1** was followed, otherwise just import mininan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f34e3-7738-41ce-a115-495619b867be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = \"~/src/minian/demo_movies/\"\n",
    "dpath = os.path.expanduser(dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a07afe-46c1-42dd-9ef1-6f3658aba527",
   "metadata": {},
   "outputs": [],
   "source": [
    "minian_path = \"~/src/minian/\"\n",
    "minian_path = os.path.expanduser(minian_path)\n",
    "minian_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019158a1-c24a-4048-8a82-7cd3841267f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(minian_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9111a-5ad9-44cb-89a9-1507992b5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    save_minian,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138719bf-140f-472a-aefe-f012cad4927d",
   "metadata": {},
   "source": [
    "The load_videos function is loading a series of .avi files as an xarray DataArray backed by Dask arrays. This means that the video data is not immediately loaded into memory; instead, Dask creates a plan (task graph) for how to load the data when necessary. This is beneficial when working with large datasets that don't fit into memory, as it allows you to perform computations in a lazy manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f901c-8590-4a0f-b8c9-e0407c8c80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "varr = load_videos(dpath, pattern='msCam[0-9]+\\\\.avi$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b2999-bde7-4c9a-b897-fbb79066aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "varr = varr.rename(\"varr\")\n",
    "varr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b06716-dbfe-4909-881f-29e5db530d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chk, _ = get_optimal_chk(varr, dtype=float)\n",
    "\n",
    "# chk[\"height\"] = -1\n",
    "# chk[\"width\"] = -1\n",
    "\n",
    "# chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a068767-6c9c-4842-b1ff-d18ae58062a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_size = 100 # chunk size of frames\n",
    "chunks = {'frame': chk_size, \"height\":-1, \"width\":-1} # chunk by set of complete frames\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f471568-1736-4a60-82c9-5a435021b866",
   "metadata": {},
   "source": [
    "We then immediately save the array representation to the intermediate folder to avoid repeatedly loading the video in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852059f-8233-4dda-ab7b-86af145bc536",
   "metadata": {},
   "outputs": [],
   "source": [
    "intpath = \"~/src/minian/minian_intermediate\"\n",
    "intpath = os.path.expanduser(intpath)\n",
    "intpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1fdd0a-7abd-4de8-b3e4-01ecaf7096d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "varr = save_minian(varr, intpath, overwrite=True, chunks=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f353a65-59f6-4441-9ed2-532026ce59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "varr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef65bbf-88f8-495b-b796-66007dbdd64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "varr.hvplot.image(groupby=\"frame\", cmap=\"Viridis\", height=400, width=400, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc099f-b7d3-4ac7-9060-02365f4e000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = varr.coords[\"frame\"].values\n",
    "slider = pn.widgets.IntSlider(start=int(frames.min()), end=int(frames.max()))\n",
    "frame = varr.interactive().isel(frame=slider)\n",
    "frame.hvplot.image(cmap=\"Viridis\", height=400, width=400, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3a8e3-7a96-4aa6-9751-a517f4093713",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 30 # frames per second\n",
    "frames = data.coords[\"frame\"].values\n",
    "\n",
    "video_player = pn.widgets.Player(\n",
    "    length=len(data.coords[\"frame\"]),\n",
    "    interval=1000//fs, # ms per frame\n",
    "    value=int(frames.min()),\n",
    "    max_width=400,\n",
    "    max_height=90,\n",
    "    loop_policy=\"loop\",\n",
    "    sizing_mode=\"stretch_width\",\n",
    ")\n",
    "\n",
    "main_h_w = data.hvplot.image(\n",
    "    groupby=\"frame\",\n",
    "    cmap=\"Viridis\",\n",
    "    frame_height=400,\n",
    "    frame_width=400,\n",
    "    colorbar=False,\n",
    "    widgets={\"frame\": video_player},\n",
    ")\n",
    "\n",
    "def update_vline(value):\n",
    "    return hv.VLine(value)\n",
    "\n",
    "def update_hline(value):\n",
    "    return hv.HLine(value)\n",
    "\n",
    "dmap_vline = hv.DynamicMap(update_vline, streams=[video_player.param.value]).opts(color='red', alpha=.6, line_width=3)\n",
    "dmap_hline = hv.DynamicMap(update_hline, streams=[video_player.param.value]).opts(color='red', alpha=.6, line_width=3)\n",
    "\n",
    "height_frame_neighbor = data.mean(['width']).hvplot.image(x='frame',\n",
    "    cmap=\"Viridis\",\n",
    "    frame_height=400,\n",
    "    frame_width=200,\n",
    "    colorbar=False,\n",
    "    title='_', # hack to ensure that xlabel is rendered, see https://github.com/bokeh/bokeh/issues/13225#issuecomment-1611172355\n",
    ") * dmap_vline\n",
    "\n",
    "# Ideally, we want the frame_width_neighbor to have yaxis inverted so it progresses away from main like height_frame_neighbor\n",
    "frame_width_neighbor = data.mean(['height']).hvplot.image(y='frame',\n",
    "    cmap=\"Viridis\",\n",
    "    frame_height=200,\n",
    "    frame_width=400,\n",
    "    colorbar=False,\n",
    "    # ylim = (data.frame.size-1,0), # this is supposed to be a inver_yaxis workaround but doesn't work here, from https://discourse.holoviz.org/t/hvplot-image-invert-y-axis/5625/2?u=droumis\n",
    ").opts(invert_yaxis=False) * dmap_hline # invert_yaxis=True doesn't work here, see https://github.com/holoviz/holoviews/issues/5801\n",
    "\n",
    "video_player.margin = (20, 20, 20, 70) # hack to center widget over main\n",
    "# main_h_w[0] below selects just the plot so we can handle the widget placement explicitly\n",
    "pn.Column(video_player, pn.Row(main_h_w[0], height_frame_neighbor), frame_width_neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca8696-1b4b-4e8a-ba8b-1f3ed903abc0",
   "metadata": {},
   "source": [
    "## Other viz implementations to ignore for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d970589-90ee-4dd1-a25a-f38a4e9adfcb",
   "metadata": {},
   "source": [
    "### Version 3: Intermediate viewer: HoloViews, frame-stream, Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55562c04-e8ee-4603-a9ff-1fcc1d8f97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = data.coords[\"frame\"].values\n",
    "f_min = int(frames.min())\n",
    "f_max = int(frames.max())\n",
    "height = data.sizes[\"height\"]\n",
    "width = data.sizes[\"width\"]\n",
    "fs = 30 # frames per second\n",
    "\n",
    "# Generate Image object for a given frame\n",
    "def generate_image(frame, data):  \n",
    "    return hv.Image(\n",
    "        data.sel(frame=frame).compute(), kdims=[\"width\", \"height\"]\n",
    "    )\n",
    "\n",
    "# Setup frame stream\n",
    "frame_param = param.Integer(default=f_min, bounds=(f_min, f_max))\n",
    "FrameStream = Stream.define(\"FrameStream\", frame=frame_param)\n",
    "frame_stream = FrameStream()\n",
    "\n",
    "# Dynamic map of image via frame stream\n",
    "image_generator = pn.bind(generate_image, data=data)\n",
    "image_map = hv.DynamicMap(image_generator, streams=[frame_stream]).opts(\n",
    "    frame_width=500, aspect=width / height, cmap=\"Viridis\"\n",
    ")\n",
    "\n",
    "# Create a video player widget\n",
    "video_player = pn.widgets.Player(\n",
    "    length=len(frames), interval=1000//fs, value=f_min, width=600, height=90\n",
    ")\n",
    "\n",
    "# update the frame stream when a new event occurs on the widget\n",
    "def update_frame_stream(event):\n",
    "    frame_stream.event(frame=int(frames[event.new]))\n",
    "\n",
    "# Link player widget to the frame stream update function\n",
    "video_player.param.watch(update_frame_stream, \"value\")\n",
    "\n",
    "layout = pn.layout.Column(video_player, image_map)\n",
    "layout.servable() # serve the app if this notebook is run on the command line with panel serve <notebook>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d10dae-78f4-4408-b555-c1a23590b5a0",
   "metadata": {},
   "source": [
    "### Version 4: Advanced Viewer (adapted Minian viewer): Class, clr hist, mask selection, summary stats, input types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e518ac6-b223-46ca-a53a-943a83a28412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate imports because this cell probably won't stay in this workflow notebook\n",
    "\n",
    "from typing import Union, List, Optional\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import param\n",
    "import functools as fct\n",
    "import itertools as itt\n",
    "from collections import OrderedDict\n",
    "from datashader import count_cat\n",
    "from holoviews.streams import Stream, BoxEdit, RangeXY\n",
    "from holoviews.operation.datashader import datashade\n",
    "import holoviews as hv; hv.extension('bokeh')\n",
    "import panel.widgets as pnwgt\n",
    "from bokeh.palettes import Category10_10\n",
    "\n",
    "\n",
    "class VArrayViewer:\n",
    "    \"\"\"\n",
    "    Interactive visualization for movie data arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    varr : Union[xr.DataArray, List[xr.DataArray], xr.Dataset]\n",
    "        Input array, list of arrays, or dataset to be visualized. Each array\n",
    "        should contain dimensions \"height\", \"width\" and \"frame\". If a\n",
    "        dataset, then the dimensions specified in `meta_dims` will be used\n",
    "        as metadata dimensions that can uniquely identify each array. If a\n",
    "        list, then a dimension \"data_var\" will be constructed and used as\n",
    "        metadata dimension, and the `.name` attribute of each array will be\n",
    "        used to identify each array.\n",
    "    framerate : int, optional\n",
    "        The framerate of playback when using the toolbar. By default `30`.\n",
    "    summary : list, optional\n",
    "        List of summary statistics to plot. The statistics should be one of\n",
    "        `{\"mean\", \"max\", \"min\", \"diff\"}`. By default `[\"mean\", \"max\"]`.\n",
    "    meta_dims : List[str], optional\n",
    "        List of dimension names that can uniquely identify each input array\n",
    "        in `varr`. Only used if `varr` is a `xr.Dataset`. By default `None`.\n",
    "    datashading : bool, optional\n",
    "        Whether to use datashading on the summary statistics. By default\n",
    "        `True`.\n",
    "    layout : bool, optional\n",
    "        Whether to visualize all arrays together as layout. If `False` then\n",
    "        only one array will be visualized and user can switch array using\n",
    "        drop-down lists below the *Play Toolbar*. By default `False`.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "        if `varr` is not a `xr.DataArray`, a `xr.Dataset` or a list of `xr.DataArray`\n",
    "    \n",
    "    More:\n",
    "    ------\n",
    "    The visualization contains following panels from top to bottom:\n",
    "\n",
    "    Play Toolbar\n",
    "        A toolbar that controls playback of the video. Additionally, when the\n",
    "        button \"Update Mask\" is clicked, the coordinates of the box drawn in\n",
    "        *Current Frame* panel will be used to update the `mask` attribute of the\n",
    "        `VArrayViewer` instance, which can be later used to subset the data. If\n",
    "        multiple arrays are visualized and `layout` is `False`, then drop-down\n",
    "        lists corresponding to each metadata dimensions will show up so the user\n",
    "        can select which array to visualize.\n",
    "    Current Frame\n",
    "        Images of the current frame. If multiple movie array are passed in,\n",
    "        multiple frames will be labeled and shown. To the side of each frame\n",
    "        there is a histogram of intensity values. The \"Box Select\" tool can be\n",
    "        used on the histogram to limit the range of intensity used for\n",
    "        color-mapping. Additionally, the \"Box Edit Tool\" is available for use on\n",
    "        the frame image, where you can hold \"Shift\" and draw a box, whose\n",
    "        coordinates can be used to update the `mask` attribute of the\n",
    "        `VarrayViewer` instance (remember to click \"Update Mask\" after drawing).\n",
    "    Summary\n",
    "        Summary statistics of each frame across time. Only shown if `summary` is\n",
    "        not empty. The red vertical line indicate current frame.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    mask : dict\n",
    "        Instance attribute that can be retrieved and used to subset data later.\n",
    "        Keys are `tuple` with values corresponding to each `meta_dims` and\n",
    "        uniquely identify each input array. If `meta_dims` is empty then keys\n",
    "        will be empty `tuple` as well. Values are `dict` mapping dimension names\n",
    "        (of the arrays) to subsetting slices. The slices are in the plotting\n",
    "        coorandinates and can be directly passed to `xr.DataArray.sel` method to\n",
    "        subset data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        varr: Union[xr.DataArray, List[xr.DataArray], xr.Dataset],\n",
    "        framerate=30,\n",
    "        summary=[\"mean\", \"max\"],\n",
    "        meta_dims: List[str] = None,\n",
    "        datashading=True,\n",
    "        layout=False,\n",
    "    ):\n",
    "        # Handling different types of `varr` input\n",
    "        if isinstance(varr, list):\n",
    "            # If `varr` is a list, assign a new coordinate `data_var` using \n",
    "            # the name of each array and concatenate them along the `data_var` dimension\n",
    "            for iv, v in enumerate(varr):\n",
    "                varr[iv] = v.assign_coords(data_var=v.name)\n",
    "            self.ds = xr.concat(varr, dim=\"data_var\")\n",
    "            meta_dims = [\"data_var\"]\n",
    "        elif isinstance(varr, xr.DataArray):\n",
    "            # If `varr` is a DataArray, convert it into a Dataset\n",
    "            self.ds = varr.to_dataset()\n",
    "        elif isinstance(varr, xr.Dataset):\n",
    "            # If `varr` is a Dataset, keep it as it is\n",
    "            self.ds = varr\n",
    "        else:\n",
    "            # If `varr` is not a list, DataArray, or Dataset, raise an error\n",
    "            raise NotImplementedError(\n",
    "                \"video array of type {} not supported\".format(type(varr))\n",
    "            )\n",
    "\n",
    "        # Initialize metadata based on the specified metadata dimensions\n",
    "        try:\n",
    "            self.meta_dicts = OrderedDict(\n",
    "                [(d, list(self.ds.coords[d].values)) for d in meta_dims]\n",
    "            )\n",
    "            self.cur_metas = OrderedDict(\n",
    "                [(d, v[0]) for d, v in self.meta_dicts.items()]\n",
    "            )\n",
    "        except TypeError:\n",
    "            self.meta_dicts = dict()\n",
    "            self.cur_metas = dict()\n",
    "\n",
    "        # Initialize some attributes\n",
    "        self._datashade = datashading\n",
    "        self._layout = layout\n",
    "        self.framerate = framerate\n",
    "        self._f = self.ds.coords[\"frame\"].values\n",
    "        self._h = self.ds.sizes[\"height\"]\n",
    "        self._w = self.ds.sizes[\"width\"]\n",
    "        self.mask = dict()\n",
    "\n",
    "        # Define streams for interaction\n",
    "        CStream = Stream.define(\n",
    "            \"CStream\",\n",
    "            f=param.Integer(\n",
    "                default=int(self._f.min()), bounds=(self._f.min(), self._f.max())\n",
    "            ),\n",
    "        )\n",
    "        self.strm_f = CStream()\n",
    "        self.str_box = BoxEdit()\n",
    "        self.widgets = self._widgets()\n",
    "\n",
    "        # Compute and store summary statistics\n",
    "        if type(summary) is list:\n",
    "            summ_all = {\n",
    "                \"mean\": self.ds.mean([\"height\", \"width\"]),\n",
    "                \"max\": self.ds.max([\"height\", \"width\"]),\n",
    "                \"min\": self.ds.min([\"height\", \"width\"]),\n",
    "                \"diff\": self.ds.diff(\"frame\").mean([\"height\", \"width\"]),\n",
    "            }\n",
    "            try:\n",
    "                summ = {k: summ_all[k] for k in summary}\n",
    "            except KeyError:\n",
    "                print(\"{} Not understood for specifying summary\".format(summary))\n",
    "            if summ:\n",
    "                # print(\"computing summary\")\n",
    "                sum_list = []\n",
    "                for k, v in summ.items():\n",
    "                    sum_list.append(v.compute().assign_coords(sum_var=k))\n",
    "                summary = xr.concat(sum_list, dim=\"sum_var\")\n",
    "        self.summary = summary\n",
    "\n",
    "        # Initialize subsets of data and summary statistics based on layout option\n",
    "        if layout:\n",
    "            self.ds_sub = self.ds\n",
    "            self.sum_sub = self.summary\n",
    "        else:\n",
    "            self.ds_sub = self.ds.sel(**self.cur_metas)\n",
    "            try:\n",
    "                self.sum_sub = self.summary.sel(**self.cur_metas)\n",
    "            except AttributeError:\n",
    "                self.sum_sub = self.summary\n",
    "\n",
    "        # Generate the panel plot\n",
    "        self.pnplot = pn.panel(self.get_hvobj())\n",
    "\n",
    "    def get_hvobj(self):\n",
    "        \"\"\"\n",
    "        Generates a holoviews Layout object of the image stack\n",
    "        \"\"\"\n",
    "        def get_im_ovly(meta):  # Function to generate overlay of image and box\n",
    "            def img(f, ds):  # Function to generate HoloViews image object for a given frame\n",
    "                return hv.Image(ds.sel(frame=f).compute(), kdims=[\"width\", \"height\"])\n",
    "\n",
    "            # Select a sub-dataset based on metadata; if not possible, use the original dataset\n",
    "            try:\n",
    "                curds = self.ds_sub.sel(**meta).rename(\"_\".join(meta.values()))\n",
    "            except ValueError:\n",
    "                curds = self.ds_sub\n",
    "\n",
    "            fim = fct.partial(img, ds=curds)  # Partial function for image generation with current dataset\n",
    "\n",
    "            # Create a dynamic map for images with the given partial function and frame stream\n",
    "            im = hv.DynamicMap(fim, streams=[self.strm_f]).opts(\n",
    "                frame_width=500, aspect=self._w / self._h, cmap=\"Viridis\"\n",
    "            )\n",
    "\n",
    "            # Define a range of x and y coordinates for the image\n",
    "            self.xyrange = RangeXY(source=im).rename(x_range=\"w\", y_range=\"h\")\n",
    "\n",
    "            # Create a box if layout is not yet defined\n",
    "            if not self._layout:\n",
    "                hv_box = hv.Polygons([]).opts(\n",
    "                    fill_alpha= 0.3, line_color= \"white\"\n",
    "                )\n",
    "                self.str_box = BoxEdit(source=hv_box)\n",
    "                im_ovly = im * hv_box  # Create an overlay of the image and the box\n",
    "            else:\n",
    "                im_ovly = im  # If layout already defined, use the image as is\n",
    "\n",
    "            def hist(f, w, h, ds):  # Function to generate histogram for given frame, width, height and dataset\n",
    "                if w and h:\n",
    "                    cur_im = hv.Image(\n",
    "                        ds.sel(frame=f).compute(), kdims=[\"width\", \"height\"]\n",
    "                    ).select(height=h, width=w)\n",
    "                else:\n",
    "                    cur_im = hv.Image(\n",
    "                        ds.sel(frame=f).compute(), kdims=[\"width\", \"height\"]\n",
    "                    )\n",
    "                return hv.operation.histogram(cur_im, num_bins=50).opts(\n",
    "                    xlabel=\"fluorescence\", ylabel=\"freq\"\n",
    "                )\n",
    "\n",
    "            fhist = fct.partial(hist, ds=curds)  # Partial function for histogram generation with current dataset\n",
    "\n",
    "            # Create a dynamic map for histograms with the given partial function and frame & xy range streams\n",
    "            his = hv.DynamicMap(fhist, streams=[self.strm_f, self.xyrange]).opts(\n",
    "                frame_height=int(500 * self._h / self._w), width=150, cmap=\"Viridis\"\n",
    "            )\n",
    "\n",
    "            # add the histogram as an adjoint subfig\n",
    "            im_ovly = im_ovly << his\n",
    "\n",
    "            return im_ovly  # Return the overlay object\n",
    "\n",
    "        # If layout is defined and metadata is available\n",
    "        if self._layout and self.meta_dicts:\n",
    "            im_dict = OrderedDict()  # Initialize an ordered dictionary to store the images\n",
    "            for meta in itt.product(*list(self.meta_dicts.values())):  # For each combination of metadata values\n",
    "                mdict = {k: v for k, v in zip(list(self.meta_dicts.keys()), meta)}  # Map each metadata key to its value\n",
    "                im_dict[meta] = get_im_ovly(mdict)  # Add the generated overlay to the dictionary\n",
    "\n",
    "            # Generate a HoloViews NdLayout object from the image dictionary\n",
    "            ims = hv.NdLayout(im_dict, kdims=list(self.meta_dicts.keys()))\n",
    "        else:\n",
    "            # If no layout or metadata, generate an overlay for the current metadata\n",
    "            ims = get_im_ovly(self.cur_metas)\n",
    "\n",
    "        if self.summary is not None:  # If summary data is available\n",
    "            # Generate a HoloViews Curve object from the summary data\n",
    "            hvsum = (\n",
    "                hv.Dataset(self.sum_sub)\n",
    "                .to(hv.Curve, kdims=[\"frame\"])\n",
    "                .overlay(\"sum_var\")\n",
    "            )\n",
    "\n",
    "            # Apply data shading if required\n",
    "            if self._datashade:\n",
    "                hvsum = datashade_ndcurve(hvsum, kdim=\"sum_var\")\n",
    "\n",
    "            try:\n",
    "                hvsum = hvsum.layout(list(self.meta_dicts.keys()))  # Arrange the summary layout based on metadata\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Generate a vertical line to indicate the current frame\n",
    "            vl = hv.DynamicMap(lambda f: hv.VLine(f), streams=[self.strm_f]).opts(\n",
    "                color=\"red\")\n",
    "\n",
    "            # Combine the summary curves and the vertical line, and apply dimensions and a colormap\n",
    "            summ = (hvsum * vl).map(\n",
    "                lambda p: p.opts(frame_width=500, aspect=3), [hv.RGB, hv.Curve]\n",
    "            )\n",
    "\n",
    "            # Combine the images and the summary into a single layout, arranged in columns\n",
    "            hvobj = (ims + summ).cols(1)\n",
    "        else:\n",
    "            hvobj = ims  # If no summary data, the layout is just the images\n",
    "\n",
    "        return hvobj  # Return the layout object\n",
    "\n",
    "\n",
    "    def show(self) -> pn.layout.Column:\n",
    "        # Return widgets and plots in a layout\n",
    "        return pn.layout.Column(self.widgets, self.pnplot)\n",
    "\n",
    "    def _widgets(self):\n",
    "        w_play = pnwgt.Player(\n",
    "            length=len(self._f), interval=1000//self.framerate, value=0, width=650, height=90\n",
    "        )\n",
    "\n",
    "        def play(f):\n",
    "            if not f.old == f.new:\n",
    "                self.strm_f.event(f=int(self._f[f.new]))\n",
    "\n",
    "        w_play.param.watch(play, \"value\")\n",
    "        w_box = pnwgt.Button(\n",
    "            name=\"Update Mask\", button_type=\"primary\", width=100, height=30\n",
    "        )\n",
    "        w_box.param.watch(self._update_box, \"clicks\")\n",
    "        if not self._layout:\n",
    "            wgt_meta = {\n",
    "                d: pnwgt.Select(name=d, options=v, height=45, width=120)\n",
    "                for d, v in self.meta_dicts.items()\n",
    "            }\n",
    "\n",
    "            def make_update_func(meta_name):\n",
    "                def _update(x):\n",
    "                    self.cur_metas[meta_name] = x.new\n",
    "                    self._update_subs()\n",
    "\n",
    "                return _update\n",
    "\n",
    "            for d, wgt in wgt_meta.items():\n",
    "                cur_update = make_update_func(d)\n",
    "                wgt.param.watch(cur_update, \"value\")\n",
    "            wgts = pn.layout.WidgetBox(w_box, w_play, *list(wgt_meta.values()))\n",
    "        else:\n",
    "            wgts = pn.layout.WidgetBox(w_box, w_play)\n",
    "        return wgts\n",
    "\n",
    "    def _update_subs(self):\n",
    "        self.ds_sub = self.ds.sel(**self.cur_metas)\n",
    "        if self.sum_sub is not None:\n",
    "            self.sum_sub = self.summary.sel(**self.cur_metas)\n",
    "        self.pnplot.objects[0].object = self.get_hvobj()\n",
    "\n",
    "    def _update_box(self, click):\n",
    "        box = self.str_box.data\n",
    "        self.mask.update(\n",
    "            {\n",
    "                tuple(self.cur_metas.values()): {\n",
    "                    \"height\": slice(box[\"y0\"][0], box[\"y1\"][0]),\n",
    "                    \"width\": slice(box[\"x0\"][0], box[\"x1\"][0]),\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "def datashade_ndcurve(\n",
    "    ovly: hv.NdOverlay, kdim: Optional[Union[str, List[str]]] = None, spread=False\n",
    ") -> hv.Overlay:\n",
    "    \"\"\"\n",
    "    Apply datashading to an overlay of curves with legends.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ovly : hv.NdOverlay\n",
    "        The input overlay of curves.\n",
    "    kdim : Union[str, List[str]], optional\n",
    "        Key dimensions of the overlay. If `None` then the first key dimension of\n",
    "        `ovly` will be used. By default `None`.\n",
    "    spread : bool, optional\n",
    "        Whether to apply :func:`holoviews.operation.datashader.dynspread` to the\n",
    "        result. By default `False`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    hvres : hv.Overlay\n",
    "        Resulting overlay of datashaded curves and points (for legends).\n",
    "    \"\"\"\n",
    "    if not kdim:\n",
    "        kdim = ovly.kdims[0].name\n",
    "    var = np.unique(ovly.dimension_values(kdim)).tolist()\n",
    "    color_key = [(v, Category10_10[iv]) for iv, v in enumerate(var)]\n",
    "    color_pts = hv.NdOverlay(\n",
    "        {\n",
    "            k: hv.Points([0, 0], label=str(k)).opts(color=v)\n",
    "            for k, v in color_key\n",
    "        }\n",
    "    )\n",
    "    ds_ovly = datashade(\n",
    "        ovly,\n",
    "        aggregator=count_cat(kdim),\n",
    "        color_key=dict(color_key),\n",
    "        min_alpha=200,\n",
    "        normalization=\"linear\",\n",
    "    )\n",
    "    if spread:\n",
    "        ds_ovly = dynspread(ds_ovly)\n",
    "    return ds_ovly * color_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9bb34-b234-4b0a-b3f9-75fb1f8c5625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vaviewer = VArrayViewer(data)\n",
    "vaviewer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e311056d-efdd-410c-9d60-8a4c2face0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ddfdec-5b82-408a-8d07-097f19cf5139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a01aebe2-1f18-467b-afb8-d2ea5d3291d1",
   "metadata": {},
   "source": [
    "# Scratch (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f1ae9-9369-4566-82d7-30d8a9b071da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd92fd-5f6e-4228-b11f-657eb5e376f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from typing import Optional, Dict, Union\n",
    "# from pathlib import Path\n",
    "# import os\n",
    "# import xarray as xr\n",
    "# import dask.array as darr\n",
    "# import shutil\n",
    "\n",
    "# # def save_minian(var: xr.DataArray, dpath: str, meta_dict: Optional[Dict[int, str]] = None,\n",
    "# #     overwrite: bool = False, compute: bool = True,) -> Union[xr.DataArray, darr.Array]:\n",
    "    \n",
    "# #     \"\"\"\n",
    "# #     Function to save a xarray DataArray to a specified path as a zarr file.\n",
    "\n",
    "# #     Parameters\n",
    "# #     ----------\n",
    "# #     var : xr.DataArray\n",
    "# #         The input xarray DataArray that needs to be saved.\n",
    "# #     dpath : str\n",
    "# #         The destination path where the file needs to be saved.\n",
    "# #     meta_dict : dict, optional\n",
    "# #         A dictionary containing metadata. If provided, it's used to assign coordinates to the dataset. \n",
    "# #         The keys are names of the coordinates and the values are the indices to be used from the pathlist. \n",
    "# #         The default is None.\n",
    "# #     overwrite : bool, optional\n",
    "# #         If true, it will overwrite the file at the destination path, if one exists. The default is False.\n",
    "\n",
    "# #     Returns\n",
    "# #     -------\n",
    "# #     Union[xr.DataArray, darr.Array]\n",
    "# #         Returns a xarray DataArray if compute is True, otherwise a Dask array.\n",
    "# #     \"\"\"\n",
    "\n",
    "# #     dpath = os.path.normpath(dpath)\n",
    "# #     Path(dpath).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# #     # Convert the DataArray to a DataSet for saving (this would happen automatically anyway if we did DataArray.to_zarr)\n",
    "# #     ds = var.to_dataset()\n",
    "    \n",
    "# #     # If there's a metadata dictionary, use it to assign coordinates to the dataset\n",
    "# #     # This is useful to include some parts of the file path as metadata in the dataset itself, \n",
    "# #     # for instance, to indicate different experimental conditions\n",
    "# #     if meta_dict is not None:\n",
    "# #         # Get the list of directories in the path\n",
    "# #         pathlist = os.path.split(os.path.abspath(dpath))[0].split(os.sep)\n",
    "        \n",
    "# #         # Assign the metadata items as coordinates to the dataset\n",
    "# #         ds = ds.assign_coords(\n",
    "# #             **dict([(dn, pathlist[di]) for dn, di in meta_dict.items()])\n",
    "# #         )\n",
    "    \n",
    "# #     # Decide the write mode based on whether we're overwriting or not\n",
    "# #     md = {True: \"a\", False: \"w-\"}[overwrite]\n",
    "    \n",
    "# #     # Set the full path to the zarr file\n",
    "# #     fp = os.path.join(dpath, var.name + \".zarr\")\n",
    "    \n",
    "# #     # If overwriting, try to remove the existing file first\n",
    "# #     if overwrite:\n",
    "# #         try:\n",
    "# #             shutil.rmtree(fp)\n",
    "# #         except FileNotFoundError:\n",
    "# #             pass  # If the file wasn't there, no problem\n",
    "    \n",
    "# #     # Save the DataSet as a zarr file\n",
    "# #     ds.to_zarr(fp, compute=compute, mode=md)\n",
    "    \n",
    "# #     # # If compute is true, open the saved zarr file, get the DataArray by name and replace the array data with the inlined zarr array\n",
    "# #     # if compute:\n",
    "# #     #     arr = xr.open_zarr(fp)[var.name]\n",
    "# #     #     arr.data = darr.from_zarr(os.path.join(fp, var.name), inline_array=True)\n",
    "    \n",
    "# #     return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
