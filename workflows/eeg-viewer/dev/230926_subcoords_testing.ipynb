{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Viewer\n",
    "![status](https://img.shields.io/badge/status-in%20progress-orange)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./assets/230524_eeg-viewer.png\" alt=\"eeg viewer preview\" width=\"450\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This workflow is intended to demonstrate the visualization of a set of 1D EEG timeseries with HoloViz and Bokeh tools.\n",
    "\n",
    "For details specific to this workflow, such as goals, specifications, and bottlenecks, please see this workflow's [readme](./readme_eeg-viewer.md).\n",
    "\n",
    "For a summary of EEG research, data, and software, please see [neuro/wiki/EEG-notes](https://github.com/holoviz-topics/neuro/wiki/EEG-notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Requirements</p>\n",
    "    <p>This workflow notebook requires the <a href=\"./environment.yml\">environment</a> specified in this workflow directory.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# HoloViz and Bokeh\n",
    "import colorcet as cc\n",
    "import holoviews as hv; hv.extension('bokeh')\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from holoviews import Dataset\n",
    "from bokeh.models import HoverTool, WheelZoomTool\n",
    "import panel as pn; pn.extension(template='material')\n",
    "\n",
    "# Neuro repo\n",
    "from neurodatagen.eeg import generate_eeg_powerlaw\n",
    "from hvneuro import download_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data pipeline\n",
    "\n",
    "The `generate_eeg_powerlaw` function synthesizes EEG data as high-pass filtered pink noise power law time series by default. The function returns a 2D numpy array of synthetic EEG data (in microvolts) shaped as (number of channels, total samples), a 1D time array (in seconds), and a list of channel names. Parameters such as the high-pass filter factor (in Hz) and an amplitude scaling factor allow customization of the generated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_channels = 25\n",
    "n_seconds = 30\n",
    "fs = 512\n",
    "\n",
    "data, time, channels = generate_eeg_powerlaw(n_channels, n_seconds, fs, channel_prefix='EEG')\n",
    "\n",
    "print(f'shape: {data.shape} (n_channels, samples) ')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max_ch_disp = 15  # max channels to initially display\n",
    "# max_t_disp = 2 # max time in seconds to initially display\n",
    "# spacing = 5.5  # Spacing between channels\n",
    "# clim_mul = 1.2 # color range multiplier for minimap. lower will saturate more.\n",
    "\n",
    "# # Annotations\n",
    "# annotation = hv.VSpan(1, 1.5) # example annotation (start, end) time\n",
    "\n",
    "# # Create a hv.Curve element per chan\n",
    "# channel_curves = []\n",
    "# max_data = data.max()\n",
    " \n",
    "# hover = HoverTool(tooltips=[\n",
    "#     (\"Channel\", \"@channel\"),\n",
    "#     (\"Time\", \"$x s\"),\n",
    "#     (\"Amplitude\", \"@original_amplitude µV\")])\n",
    "\n",
    "# offset = np.std(data) * spacing\n",
    "# for i, channel_data in enumerate(data):\n",
    "#     offset_data = channel_data + (i * offset)\n",
    "#     max_data = max(offset_data.max(), max_data) # update max\n",
    "#     ds = Dataset((time, offset_data, channel_data, channels[i]), [\"Time\", \"Amplitude\", \"original_amplitude\", \"channel\"])\n",
    "#     channel_curves.append(\n",
    "#         hv.Curve(ds, \"Time\", [\"Amplitude\", \"original_amplitude\", \"channel\"]).opts(\n",
    "#             color=\"black\", line_width=1,\n",
    "#             tools=[hover, 'xwheel_zoom'], shared_axes=False))\n",
    "\n",
    "# yticks = [(i * offset, ich) for i, ich in enumerate(channels)]\n",
    "\n",
    "# # set maintain focus to False to allow independence for zoom out against a single hardbound\n",
    "# # def set_maintain_focus(plot, element):\n",
    "# #     wheel_zoom = plot.state.select(type=WheelZoomTool)\n",
    "# #     if wheel_zoom:\n",
    "# #         wheel_zoom[0].maintain_focus = False\n",
    "        \n",
    "# # Create an overlay of curves\n",
    "# eeg_viewer = (annotation * hv.Overlay(channel_curves, kdims=\"Channel\")).opts(\n",
    "#     padding=0, xlabel=\"Time (s)\", ylabel=\"Channel\", #default_tools=['hover', 'pan', 'box_zoom', 'save', 'reset'],\n",
    "#     yticks=yticks, show_legend=False, aspect=1.5, responsive=True,\n",
    "#     shared_axes=False, backend_opts={\n",
    "#         \"x_range.bounds\": (time.min(), time.max()),\n",
    "#         \"y_range.bounds\": (data.min(), max_data)})\n",
    "\n",
    "# # Minimap\n",
    "# y_positions, _ = zip(*yticks) # use positions of yticks for yaxis of minimap image\n",
    "# z_data = zscore(data, axis=1)\n",
    "# minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"))\n",
    "# minimap = minimap.opts(\n",
    "#     cmap=\"RdBu_r\", colorbar=False, xlabel='', alpha=.8, yticks=[yticks[0], yticks[-1]],\n",
    "#     height=100, responsive=True, default_tools=[''], shared_axes=False, clim=(-z_data.std()*clim_mul, z_data.std()*clim_mul))\n",
    "\n",
    "# # Create RangeToolLink between the minimap and the main EEG viewer \n",
    "# # (quirk: apply to just one eeg trace and it will apply to all. see HoloViews #4472)\n",
    "# max_y_disp = np.max(data[max_ch_disp-1,:] + ((max_ch_disp-1) * offset))\n",
    "# RangeToolLink(minimap, list(eeg_viewer.values())[0], axes=[\"x\", \"y\"],\n",
    "#               boundsx=(None, max_t_disp),\n",
    "#               boundsy=(None, max_y_disp))\n",
    "\n",
    "# eeg_app = pn.Column((eeg_viewer + minimap * annotation).cols(1), min_height=650)#.servable(target='main', title='EEG Viewer with HoloViz and Bokeh')\n",
    "# eeg_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No subcoords, testing with simple data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import holoviews as hv\n",
    "# from bokeh.models import HoverTool\n",
    "# from holoviews.plotting.links import RangeToolLink\n",
    "# from scipy.stats import zscore\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "\n",
    "# hv.extension('bokeh')\n",
    "\n",
    "\n",
    "# N_CHANNELS = 10\n",
    "# N_SECONDS = 5\n",
    "# SAMPLING_RATE = 200\n",
    "# INIT_FREQ = 2  # Initial frequency in Hz\n",
    "# FREQ_INC = 5  # Frequency increment\n",
    "# AMPLITUDE = 1\n",
    "\n",
    "# # Generate time and channel labels\n",
    "# total_samples = N_SECONDS * SAMPLING_RATE\n",
    "# time = np.linspace(0, N_SECONDS, total_samples)\n",
    "# channels = [f'EEG {i}' for i in range(N_CHANNELS)]\n",
    "\n",
    "# # Generate sine wave data\n",
    "# data = np.array([AMPLITUDE * np.sin(2 * np.pi * (INIT_FREQ + i * FREQ_INC) * time)\n",
    "#                      for i in range(N_CHANNELS)])\n",
    "\n",
    "# max_ch_disp = 5  # max channels to initially display\n",
    "# max_t_disp = 2 # max time in seconds to initially display\n",
    "# spacing = 3.5  # Spacing between channels\n",
    "# clim_mul = 1.2 # color range multiplier for minimap. lower will saturate more.\n",
    "\n",
    "# # Annotations\n",
    "# annotation = hv.VSpan(1, 1.5) # example annotation (start, end) time\n",
    "\n",
    "# # Create a hv.Curve element per chan\n",
    "# hover = HoverTool(tooltips=[\n",
    "#     (\"Channel\", \"@channel\"),\n",
    "#     (\"Time\", \"$x s\"),\n",
    "#     (\"Amplitude\", \"@original_amplitude µV\")])\n",
    "\n",
    "# # set offset for data (non-subcoord approach)\n",
    "# offset = np.std(data) * spacing\n",
    "# offset_data = data + (np.arange(len(data))[:, np.newaxis] * offset)\n",
    "# max_data = offset_data.max()\n",
    "\n",
    "# y_positions = np.arange(len(channels)) * offset\n",
    "# yticks = list(zip(y_positions, channels))\n",
    "\n",
    "# channel_curves = []\n",
    "# for i, channel_data in enumerate(data):\n",
    "#     ds = hv.Dataset((time, offset_data[i,:], channel_data, channels[i]), \n",
    "#                  [\"Time\", \"Amplitude\", \"original_amplitude\", \"channel\"])\n",
    "#     channel_curves.append(\n",
    "#         hv.Curve(ds, \"Time\", [\"Amplitude\", \"original_amplitude\", \"channel\"]).opts(\n",
    "#             color=\"black\", line_width=1,\n",
    "#             tools=[hover, 'xwheel_zoom'], shared_axes=False))\n",
    "        \n",
    "# eeg_viewer = (annotation * hv.Overlay(channel_curves, kdims=\"Channel\")).opts(\n",
    "#     padding=0, xlabel=\"Time (s)\", ylabel=\"Channel\",\n",
    "#     yticks=yticks, show_legend=False, aspect=3, responsive=True,\n",
    "#     shared_axes=False, backend_opts={\n",
    "#         \"x_range.bounds\": (time.min(), time.max()),\n",
    "#         \"y_range.bounds\": (data.min(), max_data)})\n",
    "\n",
    "# z_data = zscore(data, axis=1)\n",
    "# minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"))\n",
    "# minimap = minimap.opts(\n",
    "#     cmap=\"RdBu_r\", colorbar=False, xlabel='', alpha=.8, yticks=[yticks[0], yticks[-1]],\n",
    "#     height=100, responsive=True, default_tools=[''], shared_axes=False,\n",
    "#     clim=(-z_data.std()*clim_mul, z_data.std()*clim_mul))\n",
    "\n",
    "# max_y_disp = np.min([N_CHANNELS+1, max_ch_disp+1])\n",
    "# RangeToolLink(minimap, eeg_viewer, axes=[\"x\", \"y\"],\n",
    "#               boundsx=(None, max_t_disp),\n",
    "#               boundsy=(None, max_y_disp))\n",
    "\n",
    "# eeg_app = (eeg_viewer + minimap * annotation).cols(1)\n",
    "# eeg_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import holoviews as hv\n",
    "# from bokeh.models import HoverTool\n",
    "# from holoviews.plotting.links import RangeToolLink\n",
    "# from scipy.stats import zscore\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "\n",
    "# hv.extension('bokeh')\n",
    "\n",
    "\n",
    "# N_CHANNELS = 10\n",
    "# N_SECONDS = 5\n",
    "# SAMPLING_RATE = 200\n",
    "# INIT_FREQ = 2  # Initial frequency in Hz\n",
    "# FREQ_INC = 5  # Frequency increment\n",
    "# AMPLITUDE = 1\n",
    "\n",
    "# # Generate time and channel labels\n",
    "# total_samples = N_SECONDS * SAMPLING_RATE\n",
    "# time = np.linspace(0, N_SECONDS, total_samples)\n",
    "# channels = [f'EEG {i}' for i in range(N_CHANNELS)]\n",
    "\n",
    "# # Generate sine wave data\n",
    "# data = np.array([AMPLITUDE * np.sin(2 * np.pi * (INIT_FREQ + i * FREQ_INC) * time)\n",
    "#                      for i in range(N_CHANNELS)])\n",
    "\n",
    "# max_ch_disp = 5  # max channels to initially display\n",
    "# max_t_disp = 2 # max time in seconds to initially display\n",
    "# spacing = 3.5  # Spacing between channels\n",
    "# clim_mul = 1.2 # color range multiplier for minimap. lower will saturate more.\n",
    "\n",
    "# # Annotations\n",
    "# annotation = hv.VSpan(1, 1.5) # example annotation (start, end) time\n",
    "\n",
    "# # Create a hv.Curve element per chan\n",
    "# hover = HoverTool(tooltips=[\n",
    "#     (\"Channel\", \"@channel\"),\n",
    "#     (\"Time\", \"$x s\"),\n",
    "#     (\"Amplitude\", \"@original_amplitude µV\")])\n",
    "\n",
    "# # set offset for data (non-subcoord approach)\n",
    "# offset = np.std(data) * spacing\n",
    "# offset_data = data + (np.arange(len(data))[:, np.newaxis] * offset)\n",
    "# max_data = offset_data.max()\n",
    "\n",
    "# y_positions = np.arange(len(channels)) * offset\n",
    "# yticks = list(zip(y_positions, channels))\n",
    "\n",
    "# channel_curves = []\n",
    "# for i, channel_data in enumerate(data):\n",
    "#     ds = hv.Dataset((time, offset_data[i,:], channel_data, channels[i]), \n",
    "#                  [\"Time\", \"Amplitude\", \"original_amplitude\", \"channel\"])\n",
    "#     channel_curves.append(\n",
    "#         hv.Curve(ds, \"Time\", [\"Amplitude\", \"original_amplitude\", \"channel\"]).opts(\n",
    "#             color=\"black\", line_width=1,\n",
    "#             tools=[hover, 'xwheel_zoom'], shared_axes=False))\n",
    "        \n",
    "# eeg_viewer = (annotation * hv.Overlay(channel_curves, kdims=\"Channel\")).opts(\n",
    "#     padding=0, xlabel=\"Time (s)\", ylabel=\"Channel\",\n",
    "#     yticks=yticks, show_legend=False, aspect=3, responsive=True,\n",
    "#     shared_axes=False, backend_opts={\n",
    "#         \"x_range.bounds\": (time.min(), time.max()),\n",
    "#         \"y_range.bounds\": (data.min(), max_data)})\n",
    "\n",
    "# z_data = zscore(data, axis=1)\n",
    "# minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"))\n",
    "# minimap = minimap.opts(\n",
    "#     cmap=\"RdBu_r\", colorbar=False, xlabel='', alpha=.8, yticks=[yticks[0], yticks[-1]],\n",
    "#     height=100, responsive=True, default_tools=[''], shared_axes=False,\n",
    "#     clim=(-z_data.std()*clim_mul, z_data.std()*clim_mul))\n",
    "\n",
    "# max_y_disp = np.max([N_CHANNELS+1, max_ch_disp+1])\n",
    "# RangeToolLink(minimap, eeg_viewer, axes=[\"x\", \"y\"],\n",
    "#               boundsx=(None, max_t_disp),\n",
    "#               boundsy=(None, max_y_disp))\n",
    "\n",
    "# eeg_app = (eeg_viewer + minimap * annotation).cols(1)\n",
    "# eeg_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subcoords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import holoviews as hv\n",
    "# from bokeh.models import HoverTool\n",
    "# from holoviews.plotting.links import RangeToolLink\n",
    "# from scipy.stats import zscore\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "\n",
    "# hv.extension('bokeh')\n",
    "\n",
    "# N_CHANNELS = 10\n",
    "# N_SECONDS = 5\n",
    "# SAMPLING_RATE = 200\n",
    "# INIT_FREQ = 2  # Initial frequency in Hz\n",
    "# FREQ_INC = 5  # Frequency increment\n",
    "# AMPLITUDE = 1\n",
    "\n",
    "# # Generate time and channel labels\n",
    "# total_samples = N_SECONDS * SAMPLING_RATE\n",
    "# time = np.linspace(0, N_SECONDS, total_samples)\n",
    "# channels = [f'EEG {i}' for i in range(N_CHANNELS)]\n",
    "\n",
    "# # Generate sine wave data\n",
    "# data = np.array([AMPLITUDE * np.sin(2 * np.pi * (INIT_FREQ + i * FREQ_INC) * time)\n",
    "#                      for i in range(N_CHANNELS)])\n",
    "\n",
    "# hover = HoverTool(tooltips=[\n",
    "#     (\"Channel\", \"@channel\"),\n",
    "#     (\"Time\", \"$x s\"),\n",
    "#     (\"Amplitude\", \"$y µV\")\n",
    "# ])\n",
    "\n",
    "# channel_curves = []\n",
    "# for channel, channel_data in zip(channels, data):\n",
    "#     ds = hv.Dataset((time, channel_data, channel), [\"Time\", \"Amplitude\", \"channel\"])\n",
    "#     curve = hv.Curve(ds, \"Time\", [\"Amplitude\", \"channel\"], label=channel)\n",
    "#     curve.opts(\n",
    "#         subcoordinate_y=True, color=\"black\", line_width=1, tools=[hover],\n",
    "#     )\n",
    "#     channel_curves.append(curve)\n",
    "\n",
    "# eeg = hv.Overlay(channel_curves, kdims=\"Channel\").opts(\n",
    "#     xlabel=\"Time (s)\", ylabel=\"Channel\", show_legend=False, aspect=3, responsive=True,\n",
    "# )\n",
    "\n",
    "# y_positions = range(N_CHANNELS)\n",
    "# yticks = [(i , ich) for i, ich in enumerate(channels)]\n",
    "\n",
    "# z_data = zscore(data, axis=1)\n",
    "\n",
    "# minimap = rasterize(hv.Image((time, y_positions , z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"))\n",
    "# minimap = minimap.opts(\n",
    "#     cmap=\"RdBu_r\", xlabel='Time (s)', alpha=.5, yticks=[yticks[0], yticks[-1]],\n",
    "#     height=150, responsive=True, default_tools=[], clim=(-z_data.std(), z_data.std())\n",
    "# )\n",
    "\n",
    "# RangeToolLink(\n",
    "#     minimap, eeg, axes=[\"x\", \"y\"],\n",
    "#     boundsx=(None, 2), boundsy=(None, 6.5)\n",
    "# )\n",
    "\n",
    "# dashboard = (eeg + minimap).opts(merge_tools=False).cols(1)\n",
    "# dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subcoords testing synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ch_disp = 20  # max channels to initially display\n",
    "max_t_disp = 20 # max time in seconds to initially display\n",
    "\n",
    "annotation = hv.VSpan(1, 1.5) # example annotation (start, end) time\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Channel\", \"@channel\"),\n",
    "    (\"Time\", \"$x s\"),\n",
    "    (\"Amplitude\", \"$y µV\")])\n",
    "\n",
    "channel_curves = []\n",
    "for channel, channel_data in zip(channels, data):\n",
    "    ds = Dataset((time, channel_data, channel), [\"Time\", \"Amplitude\", \"channel\"])\n",
    "    curve = hv.Curve(ds, \"Time\", [\"Amplitude\", \"channel\"], label=f'{channel}')\n",
    "    curve.opts(color=\"black\", line_width=1, subcoordinate_y=True, tools=[hover])\n",
    "    channel_curves.append(curve)\n",
    "\n",
    "eeg_viewer = (hv.Overlay(channel_curves, kdims=\"Channel\"))\n",
    "eeg_viewer = eeg_viewer.opts(\n",
    "    padding=0, xlabel=\"Time (s)\", ylabel=\"Channel\",\n",
    "    show_legend=False, aspect=1.5, responsive=True,\n",
    "    shared_axes=False, xlim=(time.min(), time.max()), backend_opts={\n",
    "        \"x_range.bounds\": (time.min(), time.max()),\n",
    "        \"y_range.bounds\": (-.5, len(channels)-.5)})\n",
    "\n",
    "# y_positions = range(len(channels))\n",
    "y_positions, _ = zip(*yticks)\n",
    "yticks = [(i, ich) for i, ich in enumerate(channels)]\n",
    "\n",
    "z_data = zscore(data, axis=1)\n",
    "\n",
    "minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"))\n",
    "\n",
    "clim_mul = 1.2\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\", colorbar=False, xlabel='', alpha=.5, yticks=[yticks[0], yticks[-1]],\n",
    "    height=100, responsive=True, default_tools=[], shared_axes=False, clim=(-z_data.std()*clim_mul, z_data.std()*clim_mul))\n",
    "\n",
    "# Create RangeToolLink between the minimap and the main EEG viewer \n",
    "# max_y_disp = np.max(data[max_ch_disp-1,:] + ((max_ch_disp-1) * offset))\n",
    "RangeToolLink(minimap, eeg_viewer, axes=[\"x\", \"y\"], boundsx=(None, 2), boundsy=(None, 6.5))\n",
    "\n",
    "eeg_app = (eeg_viewer + minimap).opts(merge_tools=False).cols(1)\n",
    "\n",
    "# eeg_app = pn.Column((eeg_viewer + minimap * annotations_overlay).cols(1), min_height=650)\n",
    "# eeg_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset is 2.6 MB on disk\n",
    "url = \"https://physionet.org/files/eegmmidb/1.0.0/S001/S001R04.edf?download\"\n",
    "local_data_path = \"../../data/\"\n",
    "\n",
    "# Will not download if already present at local_data_path\n",
    "local_file_path = download_file(url, local_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(local_file_path, preload=True)\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preview the channel names, types, signal ranges, and uncompressed size\n",
    "raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the real timeseries annotations and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get initial time of experiment\n",
    "orig_time = raw.annotations.orig_time\n",
    "\n",
    "# get annotations into pd df\n",
    "annotations_df = raw.annotations.to_data_frame()\n",
    "\n",
    "# Ensure the 'onset' column is in UTC timezone\n",
    "annotations_df['onset'] = annotations_df['onset'].dt.tz_localize('UTC')\n",
    "\n",
    "annotations_df['start'] = (annotations_df['onset'] - orig_time).dt.total_seconds()\n",
    "annotations_df['end'] = annotations_df['start'] + annotations_df['duration']\n",
    "\n",
    "\n",
    "unique_descriptions = annotations_df['description'].unique()\n",
    "color_map = dict(zip(unique_descriptions, cc.glasbey[:len(unique_descriptions)]))\n",
    "annotations_df['color'] = annotations_df['description'].map(color_map)\n",
    "\n",
    "annotations_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean channel names, set sensor positions, and reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the channel names\n",
    "raw.rename_channels(lambda s: s.strip(\".\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optional: preview available montages that are shipped with MNE\n",
    "# mne.channels.get_builtin_montages(descriptions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: Let's use the standard 10-20\n",
    "# montage = mne.channels.make_standard_montage(\"standard_1020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: plot the assigned positions of our data channels\n",
    "# raw.set_montage(montage, match_case=False)\n",
    "# sphere=(0, 0.015, 0, 0.099) #manually adjust the y origin coord and radius a bit\n",
    "# raw.plot_sensors(show_names=True, sphere=sphere);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-reference EEG data to the average over all recording channels\n",
    "raw.set_eeg_reference(\"average\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the data for plotting into simple numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = raw.times\n",
    "channels = raw.ch_names\n",
    "\n",
    "# get the EEG data (for this data set, all channels are EEG anyways)\n",
    "eeg_indices = mne.pick_types(raw.info, eeg=True)\n",
    "data = raw.get_data(picks=eeg_indices, units={\"eeg\":\"uV\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_ch_disp = 20  # max channels to initially display\n",
    "# max_t_disp = 20 # max time in seconds to initially display\n",
    "\n",
    "# spacing = 2.5  # Spacing between channels\n",
    "# offset = np.std(data) * spacing\n",
    "\n",
    "# # Create an overlay of VSpan annotations based on the annotations dataframe\n",
    "# annotation_elements = [hv.VSpan(row['start'], row['end']).opts(fill_color=row['color'], alpha=0.1) \n",
    "#                        for _, row in annotations_df.iterrows()]\n",
    "# annotations_overlay = hv.Overlay(annotation_elements)\n",
    "\n",
    "# # Create a hv.Curve element per chan\n",
    "# channel_curves = []\n",
    "# max_data = data.max()\n",
    " \n",
    "# hover = HoverTool(tooltips=[\n",
    "#     (\"Channel\", \"@channel\"),\n",
    "#     (\"Time\", \"$x s\"),\n",
    "#     (\"Amplitude\", \"@original_amplitude µV\")])\n",
    "\n",
    "# xwheel = WheelZoomTool(\n",
    "#     zoom_together=\"none\",\n",
    "#     dimensions=\"width\",\n",
    "#     maintain_focus=False,\n",
    "# )\n",
    "\n",
    "# for i, channel_data in enumerate(data):\n",
    "#     offset_data = channel_data + (i * offset)\n",
    "#     max_data = max(offset_data.max(), max_data) # update max\n",
    "#     ds = Dataset((time, offset_data, channel_data, channels[i]), [\"Time\", \"Amplitude\", \"original_amplitude\", \"channel\"])\n",
    "#     channel_curves.append(\n",
    "#         hv.Curve(ds, \"Time\", [\"Amplitude\", \"original_amplitude\", \"channel\"]).opts(\n",
    "#             color=\"black\", line_width=1,\n",
    "#             tools=[hover, xwheel], shared_axes=False))\n",
    "\n",
    "# yticks = [(i * offset, ich) for i, ich in enumerate(channels)]\n",
    "\n",
    "# def set_maintain_focus(plot, element):\n",
    "#     wheel_zoom = plot.state.select(type=WheelZoomTool)\n",
    "#     if wheel_zoom:\n",
    "#         wheel_zoom[0].maintain_focus = False\n",
    "\n",
    "# # Create an overlay of curves\n",
    "# eeg_viewer = (annotations_overlay * hv.Overlay(channel_curves, kdims=\"Channel\"))\n",
    "# eeg_viewer = eeg_viewer.opts(\n",
    "#     padding=0, xlabel=\"Time (s)\", ylabel=\"Channel\",\n",
    "#     yticks=yticks, show_legend=False, aspect=1.5, responsive=True,\n",
    "#     shared_axes=False, xlim=(time.min(), time.max()), backend_opts={\n",
    "#         # \"x_range.bounds\": (time.min(), time.max()),\n",
    "#         \"y_range.bounds\": (data.min(), max_data)},\n",
    "#     hooks=[set_maintain_focus])\n",
    "\n",
    "# # Get the y positions of the yticks to use as yaxis of minimap image\n",
    "# y_positions, _ = zip(*yticks)\n",
    "\n",
    "# # Compute z-scores across time for each channel\n",
    "# z_data = zscore(data, axis=1)\n",
    "\n",
    "# # Generate the zscored image for the minimap using the y tiack positions from the eeg_viewer\n",
    "# minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"))\n",
    "\n",
    "# # Style the minimap \n",
    "# clim_mul = 1.2\n",
    "# minimap = minimap.opts(\n",
    "#     cmap=\"RdBu_r\", colorbar=False, xlabel='', alpha=.5, yticks=[yticks[0], yticks[-1]],\n",
    "#     height=100, responsive=True, default_tools=[''], shared_axes=False, clim=(-z_data.std()*clim_mul, z_data.std()*clim_mul))\n",
    "    \n",
    "# # Create RangeToolLink between the minimap and the main EEG viewer \n",
    "# max_y_disp = np.max(data[max_ch_disp-1,:] + ((max_ch_disp-1) * offset))\n",
    "# RangeToolLink(minimap, list(eeg_viewer.values())[0], axes=[\"x\", \"y\"],\n",
    "#               boundsx=(None, max_t_disp),\n",
    "#               boundsy=(None, max_y_disp))\n",
    "\n",
    "# eeg_app = pn.Column((eeg_viewer + minimap * annotations_overlay).cols(1), min_height=650)\n",
    "# eeg_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subcoords testing real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ch_disp = 20  # max channels to initially display\n",
    "max_t_disp = 20 # max time in seconds to initially display\n",
    "\n",
    "spacing = 2.5  # Spacing between channels\n",
    "offset = np.std(data) * spacing\n",
    "\n",
    "# Create an overlay of VSpan annotations based on the annotations dataframe\n",
    "# annotation_elements = [hv.VSpan(row['start'], row['end']).opts(fill_color=row['color'], alpha=0.1) \n",
    "#                        for _, row in annotations_df.iterrows()]\n",
    "# annotations_overlay = hv.Overlay(annotation_elements)\n",
    "\n",
    "annotation = hv.VSpan(19, 20).opts(color='yellow', alpha=.15) # example annotation (start, end) time\n",
    "\n",
    "channel_curves = []\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Channel\", \"@channel\"),\n",
    "    (\"Time\", \"$x s\"),\n",
    "    (\"Amplitude\", \"$y µV\")])\n",
    "\n",
    "for channel, channel_data in zip(channels, data):\n",
    "    ds = Dataset((time, channel_data, channel), [\"Time\", \"Amplitude\", \"channel\"])\n",
    "    curve = hv.Curve(ds, \"Time\", [\"Amplitude\", \"channel\"], label=f'{channel}')\n",
    "    curve.opts(color=\"black\", line_width=1, subcoordinate_y=True, subcoordinate_scale=3, tools=[hover])\n",
    "    channel_curves.append(curve)\n",
    "\n",
    "eeg_viewer = (annotation*hv.Overlay(channel_curves, kdims=\"Channel\"))\n",
    "eeg_viewer = eeg_viewer.opts(\n",
    "    padding=0, xlabel=\"Time (s)\", ylabel=\"Channel\",\n",
    "    show_legend=False, aspect=2, responsive=True,\n",
    "    shared_axes=False, xlim=(time.min(), time.max()), backend_opts={\n",
    "        \"x_range.bounds\": (time.min(), time.max()),\n",
    "        \"y_range.bounds\": (0, len(channels))})\n",
    "\n",
    "\n",
    "y_positions = range(len(channels))\n",
    "yticks = [(i, ich) for i, ich in enumerate(channels)]\n",
    "\n",
    "z_data = zscore(data, axis=1)\n",
    "\n",
    "minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"))\n",
    "\n",
    "clim_mul = 3\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\", colorbar=False, xlabel='', alpha=.5, yticks=[yticks[0], yticks[-1]],\n",
    "    height=125, responsive=True, default_tools=[], shared_axes=False, clim=(-z_data.std()*clim_mul, z_data.std()*clim_mul))\n",
    "\n",
    "# Create RangeToolLink between the minimap and the main EEG viewer \n",
    "# max_y_disp = np.max(data[max_ch_disp-1,:] + ((max_ch_disp-1) * offset))\n",
    "RangeToolLink(minimap, eeg_viewer, axes=[\"x\", \"y\"], boundsx=(15, 25), boundsy=(17, 33))\n",
    "\n",
    "eeg_app = (eeg_viewer + minimap*annotation).opts(merge_tools=False).cols(1)\n",
    "\n",
    "# eeg_app = pn.Column((eeg_viewer + minimap * annotations_overlay).cols(1), min_height=650)\n",
    "eeg_app = pn.Column((eeg_viewer + minimap * annotation).cols(1), min_height=650).servable(target='main', title='EEG Viewer with HoloViz and Bokeh')\n",
    "eeg_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
